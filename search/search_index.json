{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83d\ude80 Basic gRPC Service Documentation","text":"<p>Welcome to the Basic gRPC Service documentation! This is a modern Python gRPC service that showcases:</p> <ul> <li>\ud83d\udd04 Bidirectional streaming with real-time chat</li> <li>\u26a1 Async/await everywhere for performance</li> <li>\ud83c\udfad Background task orchestration with live updates</li> <li>\u2601\ufe0f CloudEvents integration for event-driven architecture</li> <li>\ud83d\udd10 TLS/SSL security with certificates</li> <li>\ud83c\udfe5 Health checks and reflection built-in</li> </ul>"},{"location":"#quick-navigation","title":"\ud83c\udfaf Quick Navigation","text":"<ul> <li> <p> Getting Started</p> <p>Jump right in with installation and setup instructions</p> </li> <li> <p> API Reference</p> <p>Complete documentation of all classes and methods</p> </li> <li> <p> Examples</p> <p>Code examples and usage patterns</p> </li> <li> <p> Development</p> <p>Contributing and development guidelines</p> </li> </ul>"},{"location":"#key-features","title":"\ud83c\udf1f Key Features","text":""},{"location":"#real-time-communication","title":"Real-time Communication","text":"<p>Our service supports bidirectional streaming, perfect for chat applications and real-time data feeds.</p>"},{"location":"#background-processing","title":"Background Processing","text":"<p>Demonstrate parallel task execution with the Background method - run multiple tasks and get live progress updates.</p>"},{"location":"#enterprise-ready","title":"Enterprise Ready","text":"<p>Built with CloudEvents, structured logging, health checks, and graceful shutdown handling.</p>"},{"location":"#architecture","title":"\ud83d\udd27 Architecture","text":"<pre><code>graph TB\n    Client[gRPC Client] --&gt;|TLS/HTTP2| Server[gRPC Server]\n    Server --&gt; Hello[Hello Service&lt;br/&gt;Unary RPC]\n    Server --&gt; Talk[Talk Service&lt;br/&gt;Bidirectional Stream]\n    Server --&gt; Background[Background Service&lt;br/&gt;Server Stream]\n    Talk --&gt; Eliza[Eliza Chatbot]\n    Background --&gt; Workers[Background Workers]\n    Server --&gt; Health[Health Check]\n    Server --&gt; Reflection[Server Reflection]</code></pre> <p>Ready to dive in? Start with our Getting Started guide!</p>"},{"location":"development/","title":"\ud83d\udd27 Development Guide","text":"<p>Welcome to the development guide! Here's everything you need to know about contributing to and developing the Basic gRPC Service.</p>"},{"location":"development/#development-setup","title":"\ud83d\udee0\ufe0f Development Setup","text":""},{"location":"development/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10+</li> <li>buf CLI (optional, for protobuf management)</li> <li>mkcert for local TLS certificates</li> <li>grpcurl for testing</li> </ul>"},{"location":"development/#environment-setup","title":"Environment Setup","text":"<pre><code># Clone the repository\ngit clone &lt;your-repo-url&gt;\ncd basic-grpc-service-python\n\n# Set up Python path for development\nexport PYTHONPATH=\"$PYTHONPATH:$(pwd):$(pwd)/sdk:$(pwd)/services:$(pwd)/utils\"\n\n# Install in development mode\npython -m pip install -e .\n\n# Install development dependencies\npip install -e \".[dev,docs]\"\n</code></pre>"},{"location":"development/#project-structure","title":"\ud83d\udce6 Project Structure","text":"<pre><code>basic-grpc-service-python/\n\u251c\u2500\u2500 \ud83d\udcc1 proto/                    # Protocol Buffer definitions\n\u2502   \u251c\u2500\u2500 basic/v1/basic.proto     # Main service definitions\n\u2502   \u2514\u2500\u2500 basic/service/v1/        # Message types and events\n\u251c\u2500\u2500 \ud83d\udcc1 sdk/                      # Generated Python code\n\u2502   \u251c\u2500\u2500 basic/                   # Auto-generated from protos\n\u2502   \u2514\u2500\u2500 cloudevents/             # CloudEvents protobuf\n\u251c\u2500\u2500 \ud83d\udcc1 services/                 # Service implementations\n\u2502   \u251c\u2500\u2500 __init__.py              # Package initialization\n\u2502   \u2514\u2500\u2500 basic_service.py         # Main service logic\n\u251c\u2500\u2500 \ud83d\udcc1 utils/                    # Utility modules\n\u2502   \u251c\u2500\u2500 __init__.py              # Package exports\n\u2502   \u251c\u2500\u2500 eliza.py                 # Eliza chatbot implementation\n\u2502   \u2514\u2500\u2500 some.py                  # Helper utilities\n\u251c\u2500\u2500 \ud83d\udcc1 docs/                     # MkDocs documentation\n\u251c\u2500\u2500 \ud83d\udcc1 certs/                    # TLS certificates\n\u251c\u2500\u2500 \ud83d\udc0d server.py                 # Main server entry point\n\u251c\u2500\u2500 \ud83d\udccb pyproject.toml            # Python project configuration\n\u251c\u2500\u2500 \ud83d\udee1\ufe0f buf.yaml                  # Buf configuration\n\u2514\u2500\u2500 \u2699\ufe0f buf.gen.yaml              # Code generation config\n</code></pre>"},{"location":"development/#code-generation","title":"\ud83d\udd04 Code Generation","text":"<p>This project uses Buf for protobuf management and code generation.</p>"},{"location":"development/#regenerating-python-code","title":"Regenerating Python Code","text":"<p>When you modify <code>.proto</code> files, regenerate the Python code:</p> <pre><code># Using buf (recommended)\nbuf generate\n\n# Or using protoc directly (if you don't have buf)\nprotoc --python_out=sdk --pyi_out=sdk --grpc_python_out=sdk proto/basic/v1/*.proto\n</code></pre>"},{"location":"development/#generated-files","title":"Generated Files","text":"<p>The code generation creates: - Regular Python modules (<code>*_pb2.py</code>) - gRPC service stubs (<code>*_pb2_grpc.py</code>) - Type stubs (<code>*.pyi</code>) for better IDE support - Package <code>__init__.py</code> files automatically</p>"},{"location":"development/#testing","title":"\ud83e\uddea Testing","text":""},{"location":"development/#manual-testing-with-grpcurl","title":"Manual Testing with grpcurl","text":"<pre><code># Start the server\npython server.py\n\n# Test the services\ngrpcurl -insecure -d '{\"message\": \"test\"}' 127.0.0.1:8443 basic.v1.BasicService/Hello\n</code></pre>"},{"location":"development/#health-checks","title":"Health Checks","text":"<pre><code># Server health\ngrpcurl -insecure 127.0.0.1:8443 grpc.health.v1.Health/Check\n\n# Service-specific health\ngrpcurl -insecure -d '{\"service\": \"basic.v1.BasicService\"}' \\\n  127.0.0.1:8443 grpc.health.v1.Health/Check\n</code></pre>"},{"location":"development/#documentation-development","title":"\ud83d\udcda Documentation Development","text":"<p>This project uses MkDocs with the Material theme for documentation.</p>"},{"location":"development/#building-documentation","title":"Building Documentation","text":"<pre><code># Install documentation dependencies\npip install mkdocs mkdocs-material mkdocstrings[python] mkdocs-gen-files mkdocs-literate-nav mkdocs-section-index\n\n# Serve documentation locally\nmkdocs serve\n\n# Build static documentation\nmkdocs build\n</code></pre>"},{"location":"development/#documentation-structure","title":"Documentation Structure","text":"<ul> <li><code>docs/</code> - Markdown documentation files</li> <li><code>docs/gen_ref_pages.py</code> - Auto-generates API reference from docstrings</li> <li><code>mkdocs.yml</code> - MkDocs configuration</li> </ul>"},{"location":"development/#writing-documentation","title":"Writing Documentation","text":"<ul> <li>Use emoji for visual appeal \ud83c\udfa8</li> <li>Include code examples with proper syntax highlighting</li> <li>Add cross-references between sections</li> <li>Keep it conversational but professional</li> </ul>"},{"location":"development/#code-style","title":"\ud83c\udfa8 Code Style","text":""},{"location":"development/#docstring-style","title":"Docstring Style","text":"<p>We use a fun, engaging docstring style with emojis and personality:</p> <pre><code>def example_function(param: str) -&gt; str:\n    \"\"\"\n    \ud83c\udf89 This function does something awesome!\n\n    A detailed description of what this function does, why it exists,\n    and how it fits into the bigger picture. Include personality and\n    make it fun to read!\n\n    Args:\n        param (str): Description of the parameter with examples\n\n    Returns:\n        str: What gets returned and when\n\n    Raises:\n        ValueError: When something goes wrong and why\n\n    Example:\n        &gt;&gt;&gt; result = example_function(\"test\")\n        &gt;&gt;&gt; print(result)\n        \"processed: test\"\n\n    Note:\n        Any important notes, warnings, or tips for users!\n    \"\"\"\n</code></pre>"},{"location":"development/#type-hints","title":"Type Hints","text":"<ul> <li>Use type hints everywhere</li> <li>Import types from <code>typing</code> when needed</li> <li>Use generic types for containers (<code>List[str]</code>, <code>Dict[str, Any]</code>)</li> </ul>"},{"location":"development/#debugging","title":"\ud83d\udc1b Debugging","text":""},{"location":"development/#logging","title":"Logging","text":"<p>The server uses structured JSON logging:</p> <pre><code>import logging\nlogging.info(\"Something happened\", extra={\"key\": \"value\"})\n</code></pre>"},{"location":"development/#common-issues","title":"Common Issues","text":"<ol> <li>Import Errors: Make sure <code>PYTHONPATH</code> includes all necessary directories</li> <li>Certificate Issues: Regenerate with <code>mkcert</code></li> <li>Port Conflicts: Check if port 8443 is already in use</li> </ol>"},{"location":"development/#python-path-issues","title":"Python Path Issues","text":"<p>For pydoc and development:</p> <pre><code>export PYTHONPATH=\"$PYTHONPATH:$(pwd):$(pwd)/sdk:$(pwd)/services:$(pwd)/utils\"\n</code></pre>"},{"location":"development/#deployment","title":"\ud83d\ude80 Deployment","text":""},{"location":"development/#building-for-production","title":"Building for Production","text":"<pre><code># Build documentation\nmkdocs build\n\n# The documentation will be in site/\n</code></pre>"},{"location":"development/#github-pages-deployment","title":"GitHub Pages Deployment","text":"<pre><code># Deploy documentation to GitHub Pages\nmkdocs gh-deploy\n</code></pre>"},{"location":"development/#contributing","title":"\ud83e\udd1d Contributing","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make your changes with proper documentation</li> <li>Test your changes thoroughly</li> <li>Submit a pull request</li> </ol>"},{"location":"development/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<ul> <li>Include clear descriptions of changes</li> <li>Add documentation for new features</li> <li>Maintain the fun, engaging tone in docstrings</li> <li>Test with both pydoc and MkDocs</li> </ul> <p>Ready to contribute? The codebase is designed to be approachable and fun to work with! \ud83c\udf89</p>"},{"location":"examples/","title":"\ud83c\udfae Examples","text":"<p>Here are practical examples showing how to use the Basic gRPC Service in different scenarios.</p>"},{"location":"examples/#python-client-examples","title":"\ud83e\udd16 Python Client Examples","text":""},{"location":"examples/#simple-hello-client","title":"Simple Hello Client","text":"<pre><code># File: examples/hello_client.py\nimport asyncio\nimport grpc\nfrom basic.v1 import basic_pb2_grpc\nfrom basic.service.v1 import service_pb2\n\nasync def simple_hello():\n    \"\"\"Simple example calling the Hello method.\"\"\"\n    async with grpc.aio.insecure_channel('127.0.0.1:8443') as channel:\n        stub = basic_pb2_grpc.BasicServiceStub(channel)\n\n        request = service_pb2.HelloRequest(message=\"MkDocs User\")\n        response = await stub.Hello(request)\n\n        print(f\"\u2705 Server responded with CloudEvent:\")\n        print(f\"   ID: {response.cloud_event.id}\")\n        print(f\"   Source: {response.cloud_event.source}\")\n        print(f\"   Type: {response.cloud_event.type}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(simple_hello())\n</code></pre>"},{"location":"examples/#chat-client-with-eliza","title":"Chat Client with Eliza","text":"<pre><code># File: examples/chat_client.py\nimport asyncio\nimport grpc\nfrom basic.v1 import basic_pb2_grpc\nfrom basic.service.v1 import service_pb2\n\nasync def chat_with_eliza():\n    \"\"\"Interactive chat with the Eliza chatbot.\"\"\"\n    async with grpc.aio.insecure_channel('127.0.0.1:8443') as channel:\n        stub = basic_pb2_grpc.BasicServiceStub(channel)\n\n        # Messages to send\n        messages = [\n            \"Hello there!\",\n            \"I am feeling a bit sad today\",\n            \"My mother never understood me\",\n            \"Do you think that's normal?\",\n            \"Goodbye\"\n        ]\n\n        async def generate_requests():\n            for msg in messages:\n                print(f\"\ud83d\udc64 You: {msg}\")\n                yield service_pb2.TalkRequest(message=msg)\n                await asyncio.sleep(1)  # Pause between messages\n\n        # Start the conversation\n        async for response in stub.Talk(generate_requests()):\n            print(f\"\ud83e\udde0 Eliza: {response.answer}\")\n            print()\n\nif __name__ == \"__main__\":\n    asyncio.run(chat_with_eliza())\n</code></pre>"},{"location":"examples/#background-tasks-client","title":"Background Tasks Client","text":"<pre><code># File: examples/background_client.py\nimport asyncio\nimport grpc\nfrom basic.v1 import basic_pb2_grpc\nfrom basic.service.v1 import service_pb2\n\nasync def monitor_background_tasks():\n    \"\"\"Monitor background task execution with live updates.\"\"\"\n    async with grpc.aio.insecure_channel('127.0.0.1:8443') as channel:\n        stub = basic_pb2_grpc.BasicServiceStub(channel)\n\n        # Request 5 background processes\n        request = service_pb2.BackgroundRequest(processes=5)\n\n        print(\"\ud83d\ude80 Starting background tasks...\")\n        print(\"\ud83d\udcca Monitoring progress:\\n\")\n\n        async for response in stub.Background(request):\n            event = response.cloud_event\n\n            # Extract the actual event data (this requires protobuf unpacking)\n            print(f\"\ud83d\udcc5 Event ID: {event.id}\")\n            print(f\"\ud83d\udccd Source: {event.source}\")\n            print(f\"\u23f0 Time: {event.attributes['time'].ce_timestamp}\")\n            print(f\"\ud83d\udce6 Responses collected: {len(response.cloud_event.proto_data)}\")\n            print(\"---\")\n\nif __name__ == \"__main__\":\n    asyncio.run(monitor_background_tasks())\n</code></pre>"},{"location":"examples/#using-grpcurl-command-line","title":"\ud83c\udf10 Using grpcurl (Command Line)","text":""},{"location":"examples/#basic-service-discovery","title":"Basic Service Discovery","text":"<pre><code># Discover all available services\ngrpcurl -insecure 127.0.0.1:8443 list\n\n# List methods for BasicService\ngrpcurl -insecure 127.0.0.1:8443 list basic.v1.BasicService\n\n# Get service description\ngrpcurl -insecure 127.0.0.1:8443 describe basic.v1.BasicService\n</code></pre>"},{"location":"examples/#hello-method-examples","title":"Hello Method Examples","text":"<pre><code># Simple hello\ngrpcurl -insecure -d '{\"message\": \"World\"}' \\\n  127.0.0.1:8443 basic.v1.BasicService/Hello\n\n# Hello with custom message\ngrpcurl -insecure -d '{\"message\": \"MkDocs Documentation\"}' \\\n  127.0.0.1:8443 basic.v1.BasicService/Hello\n</code></pre>"},{"location":"examples/#talk-method-examples","title":"Talk Method Examples","text":"<pre><code># Single message chat\necho '{\"message\": \"Hello Eliza!\"}' | \\\n  grpcurl -insecure -d @ 127.0.0.1:8443 basic.v1.BasicService/Talk\n\n# Multi-message conversation\ncat &lt;&lt;EOF | grpcurl -insecure -d @ 127.0.0.1:8443 basic.v1.BasicService/Talk\n{\"message\": \"Hello there\"}\n{\"message\": \"I feel anxious today\"}\n{\"message\": \"What should I do?\"}\n{\"message\": \"Thank you for listening\"}\n{\"message\": \"Goodbye\"}\nEOF\n</code></pre>"},{"location":"examples/#background-method-examples","title":"Background Method Examples","text":"<pre><code># Run 3 background processes\ngrpcurl -insecure -d '{\"processes\": 3}' \\\n  127.0.0.1:8443 basic.v1.BasicService/Background\n\n# Run 10 background processes (stress test!)\ngrpcurl -insecure -d '{\"processes\": 10}' \\\n  127.0.0.1:8443 basic.v1.BasicService/Background\n</code></pre>"},{"location":"examples/#health-check-examples","title":"\ud83c\udfe5 Health Check Examples","text":"<pre><code># Check overall server health\ngrpcurl -insecure 127.0.0.1:8443 grpc.health.v1.Health/Check\n\n# Check BasicService specifically\ngrpcurl -insecure -d '{\"service\": \"basic.v1.BasicService\"}' \\\n  127.0.0.1:8443 grpc.health.v1.Health/Check\n\n# Watch health status (streaming)\ngrpcurl -insecure -d '{\"service\": \"basic.v1.BasicService\"}' \\\n  127.0.0.1:8443 grpc.health.v1.Health/Watch\n</code></pre>"},{"location":"examples/#debugging-and-development","title":"\ud83d\udc1b Debugging and Development","text":""},{"location":"examples/#server-reflection-examples","title":"Server Reflection Examples","text":"<pre><code># List all services (including reflection and health)\ngrpcurl -insecure 127.0.0.1:8443 list\n\n# Get full service descriptor\ngrpcurl -insecure 127.0.0.1:8443 describe basic.v1.BasicService.Hello\n\n# Explore message types\ngrpcurl -insecure 127.0.0.1:8443 describe basic.service.v1.HelloRequest\n</code></pre>"},{"location":"examples/#testing-error-scenarios","title":"Testing Error Scenarios","text":"<pre><code># Test with invalid JSON (should fail gracefully)\ngrpcurl -insecure -d '{\"invalid\": \"data\"}' \\\n  127.0.0.1:8443 basic.v1.BasicService/Hello\n\n# Test with missing fields\ngrpcurl -insecure -d '{}' \\\n  127.0.0.1:8443 basic.v1.BasicService/Hello\n</code></pre> <p>These examples demonstrate the flexibility and power of your gRPC service! Try them out and see the beautiful responses with CloudEvents, real-time streaming, and background processing in action. \ud83c\udf89</p>"},{"location":"getting-started/","title":"\ud83d\ude80 Getting Started","text":"<p>Get up and running with the Basic gRPC Service in just a few minutes!</p>"},{"location":"getting-started/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"<p>Before we begin, make sure you have:</p> <ul> <li>Python 3.10+ (because we love modern Python! \ud83d\udc0d)</li> <li>pip for package management</li> <li>mkcert for generating local TLS certificates</li> </ul>"},{"location":"getting-started/#installation","title":"\ud83d\udd27 Installation","text":""},{"location":"getting-started/#1-generate-tls-certificates","title":"1. Generate TLS Certificates","text":"<p>First, let's create some local certificates for secure communication:</p> <pre><code># Install mkcert (choose your platform)\n# macOS: brew install mkcert\n# Windows: choco install mkcert\n# Linux: check your package manager\n\n# Install the local Certificate Authority\nmkcert -install\n\n# Generate certificates for localhost\nmkdir -p certs\nmkcert -cert-file ./certs/local.crt -key-file ./certs/local.key localhost 127.0.0.1 0.0.0.0 ::1\n</code></pre>"},{"location":"getting-started/#2-install-dependencies","title":"2. Install Dependencies","text":"<pre><code># Install the project in development mode\npython -m pip install -e .\n</code></pre> <p>This will install all required dependencies including gRPC, protobuf, and logging libraries.</p>"},{"location":"getting-started/#3-set-up-python-path","title":"3. Set Up Python Path","text":"<p>For development and documentation generation, set up your Python path:</p> <pre><code>export PYTHONPATH=\"$PYTHONPATH:$(pwd):$(pwd)/sdk:$(pwd)/services:$(pwd)/utils\"\n</code></pre>"},{"location":"getting-started/#running-the-server","title":"\ud83c\udfac Running the Server","text":"<p>Start the gRPC server:</p> <pre><code>python server.py\n</code></pre> <p>You should see JSON-formatted log output indicating the server is running:</p> <pre><code>{\"level\": \"INFO\", \"message\": \"gRPC server listening on https://127.0.0.1:8443 (HTTP/2)\", \"time\": \"2024-01-01T12:00:00.000Z\"}\n</code></pre> <p>The server is now running on <code>https://127.0.0.1:8443</code> with TLS encryption! \ud83d\udd10</p>"},{"location":"getting-started/#testing-the-service","title":"\ud83c\udfae Testing the Service","text":""},{"location":"getting-started/#using-grpcurl","title":"Using grpcurl","text":"<p>grpcurl is the best way to test gRPC services:</p> <pre><code># Discover services\ngrpcurl -insecure 127.0.0.1:8443 list\n\n# Say hello\ngrpcurl -insecure -d '{\"message\": \"World\"}' \\\n  127.0.0.1:8443 basic.v1.BasicService/Hello\n\n# Start a conversation\ngrpcurl -insecure -d '{\"message\": \"Hello!\"}' \\\n  127.0.0.1:8443 basic.v1.BasicService/Talk\n\n# Run background tasks\ngrpcurl -insecure -d '{\"processes\": 3}' \\\n  127.0.0.1:8443 basic.v1.BasicService/Background\n</code></pre>"},{"location":"getting-started/#health-checks","title":"Health Checks","text":"<p>The server includes built-in health checking:</p> <pre><code># Check overall health\ngrpcurl -insecure 127.0.0.1:8443 grpc.health.v1.Health/Check\n\n# Check specific service\ngrpcurl -insecure -d '{\"service\": \"basic.v1.BasicService\"}' \\\n  127.0.0.1:8443 grpc.health.v1.Health/Check\n</code></pre>"},{"location":"getting-started/#python-client-example","title":"\ud83d\udc0d Python Client Example","text":"<p>Create a simple client to interact with your service:</p> <pre><code>import asyncio\nimport grpc\nfrom basic.v1 import basic_pb2_grpc\nfrom basic.service.v1 import service_pb2\n\nasync def main():\n    # Connect to the server (insecure for local dev)\n    channel = grpc.aio.insecure_channel('127.0.0.1:8443')\n    stub = basic_pb2_grpc.BasicServiceStub(channel)\n\n    try:\n        # Call the Hello method\n        request = service_pb2.HelloRequest(message=\"Python Client\")\n        response = await stub.Hello(request)\n        print(f\"Response: {response}\")\n\n    finally:\n        await channel.close()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"getting-started/#next-steps","title":"\ud83c\udfaf Next Steps","text":"<p>Now that you have the service running:</p> <ul> <li>\ud83d\udcd6 Explore the API Reference to understand all available methods</li> <li>\ud83d\udcac Try the Talk service for real-time chat</li> <li>\ud83c\udfc3\u200d\u2642\ufe0f Test the Background service for parallel processing</li> <li>\ud83e\udde0 Learn about the Eliza chatbot implementation</li> </ul> <p>Ready to dive deeper? Check out our Examples page for more advanced usage patterns!</p>"},{"location":"reference/","title":"API Reference","text":"<p>Welcome to the API documentation! Here you'll find detailed information about all the modules and their functions.</p>"},{"location":"reference/#available-modules","title":"\ud83d\udcda Available Modules","text":""},{"location":"reference/#server","title":"Server","text":"<p>Main gRPC server implementation</p>"},{"location":"reference/#basic-service","title":"Basic Service","text":"<p>gRPC service implementation with Hello, Talk, and Background methods</p>"},{"location":"reference/#eliza-chatbot","title":"Eliza Chatbot","text":"<p>Classic ELIZA therapeutic chatbot implementation</p>"},{"location":"reference/#utilities","title":"Utilities","text":"<p>Helper functions for CloudEvents and service simulation</p>"},{"location":"reference/server/","title":"Server","text":"<p>Main gRPC server implementation</p>"},{"location":"reference/server/#server","title":"server","text":"<p>\ud83d\ude80 Basic gRPC Service Server</p> <p>A delightfully secure and robust gRPC server implementation that serves your basic service with TLS encryption, health checks, and graceful shutdown capabilities. Because who doesn't love a server that knows how to say goodbye properly? \ud83d\udc4b</p> <p>This module provides the main server entry point for the Basic gRPC service, complete with: - SSL/TLS security (because security is not optional!) - Health checking (to keep your service feeling great) - Server reflection (for introspection and debugging) - Graceful shutdown handling (because abrupt endings are for bad movies)</p> Example <p>Run the server directly from the command line:</p> <p>$ python server.py</p> <p>The server will start listening on https://127.0.0.1:8443 with JSON logging.</p> <p>Author: The gRPC Wizards \u2728</p>"},{"location":"reference/server/#server-functions","title":"Functions","text":""},{"location":"reference/server/#server.serve","title":"serve  <code>async</code>","text":"<pre><code>serve()\n</code></pre> <p>\ud83c\udfaa The main circus tent where all the gRPC magic happens!</p> <p>Spins up a fully-featured gRPC server with all the bells and whistles: - TLS encryption using local certificates - Service implementation registration - Health check endpoint (because health matters!) - Server reflection for easy debugging - Graceful shutdown handling (the polite way to exit)</p> <p>The server listens on 127.0.0.1:8443 and uses HTTP/2 for that modern touch. When shutdown signals are received (SIGINT, SIGTERM), the server gracefully stops accepting new requests and allows existing ones up to 10 seconds to complete.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the TLS certificate files are missing from certs/</p> <code>RpcError</code> <p>If there are issues starting the gRPC server</p> Note <p>Make sure you have valid TLS certificates in the certs/ directory: - certs/local.crt (certificate file) - certs/local.key (private key file)</p> Source code in <code>server.py</code> <pre><code>async def serve() -&gt; None:\n    \"\"\"\n    \ud83c\udfaa The main circus tent where all the gRPC magic happens!\n\n    Spins up a fully-featured gRPC server with all the bells and whistles:\n    - TLS encryption using local certificates\n    - Service implementation registration\n    - Health check endpoint (because health matters!)\n    - Server reflection for easy debugging\n    - Graceful shutdown handling (the polite way to exit)\n\n    The server listens on 127.0.0.1:8443 and uses HTTP/2 for that modern touch.\n    When shutdown signals are received (SIGINT, SIGTERM), the server gracefully\n    stops accepting new requests and allows existing ones up to 10 seconds to complete.\n\n    Raises:\n        FileNotFoundError: If the TLS certificate files are missing from certs/\n        grpc.RpcError: If there are issues starting the gRPC server\n\n    Note:\n        Make sure you have valid TLS certificates in the certs/ directory:\n        - certs/local.crt (certificate file)\n        - certs/local.key (private key file)\n    \"\"\"\n    # Load TLS credentials like a boss \ud83d\udd10\n    # (Because plain HTTP is so 1990s)\n    with open(\"certs/local.crt\", \"rb\") as f:\n        cert = f.read()\n    with open(\"certs/local.key\", \"rb\") as f:\n        key = f.read()\n\n    server_creds = grpc.ssl_server_credentials(\n        private_key_certificate_chain_pairs=[(key, cert)],\n        root_certificates=None,\n        require_client_auth=False,  # We're friendly, no client certs required\n    )\n\n    # Create our shiny new server instance\n    server = grpc.aio.server()\n\n    # Register our basic service implementation\n    # (This is where the actual business logic lives!)\n    basic_pb2_grpc.add_BasicServiceServicer_to_server(BasicServiceImpl(), server)\n\n    # Enable reflection for debugging and introspection\n    # (Because sometimes you need to look in the mirror)\n    reflection.enable_server_reflection([\n        basic_pb2.DESCRIPTOR.services_by_name['BasicService'].full_name\n    ], server)\n\n    # Set up health checking service\n    # (Keep your service healthy, just like eating your vegetables \ud83e\udd55)\n    health_servicer = health.HealthServicer(\n        experimental_non_blocking=True,\n        experimental_thread_pool=futures.ThreadPoolExecutor(max_workers=10),\n    )\n\n    # Set health status for the overall server and specific service\n    health_servicer.set(\"\", health_pb2.HealthCheckResponse.UNKNOWN)\n    health_servicer.set(\n        basic_pb2.DESCRIPTOR.services_by_name['BasicService'].full_name,\n        health_pb2.HealthCheckResponse.SERVING\n    )\n\n    health_pb2_grpc.add_HealthServicer_to_server(health_servicer, server)\n\n    # Bind to our local address with TLS\n    server.add_secure_port(\"127.0.0.1:8443\", server_creds)\n\n    # \ud83d\ude80 Launch sequence initiated!\n    await server.start()\n    logging.info(\"gRPC server listening on https://127.0.0.1:8443 (HTTP/2)\")\n\n    # ---- Graceful shutdown orchestration ----\n    # (Because good servers know how to make a graceful exit)\n    stop_event = asyncio.Event()\n    loop = asyncio.get_running_loop()\n\n    def _signal_handler() -&gt; None:\n        \"\"\"\n        \ud83d\uded1 The polite way to ask the server to stop.\n\n        This signal handler sets the stop event, which triggers the graceful\n        shutdown sequence. It's idempotent, so multiple signals won't cause issues.\n        Think of it as the server's \"please wrap up what you're doing\" bell.\n        \"\"\"\n        stop_event.set()\n\n    # Register signal handlers for graceful shutdown\n    # (SIGINT = Ctrl+C, SIGTERM = polite termination request)\n    for sig in (signal.SIGINT, signal.SIGTERM):\n        try:\n            loop.add_signal_handler(sig, _signal_handler)\n        except NotImplementedError:\n            # Windows or environments that don't support signal handling in event loops\n            # (Windows, you're special, but not in a bad way... mostly)\n            pass\n\n    # Wait for the stop signal like a patient butler\n    await stop_event.wait()\n\n    logging.info(\"Shutting down gracefully... (waiting up to 10s for in-flight RPCs)\")\n\n    # Grace period: Stop accepting new requests, allow existing ones to complete\n    # (10 seconds should be enough for most polite RPCs to finish their business)\n    await server.stop(grace=10.0)\n    logging.info(\"Shutdown complete. Thanks for using our service! \ud83d\udc4b\")\n</code></pre>"},{"location":"reference/services.basic_service/","title":"Basic Service","text":"<p>gRPC service implementation with Hello, Talk, and Background methods</p>"},{"location":"reference/services.basic_service/#services.basic_service","title":"basic_service","text":"<p>\ud83c\udfaa Basic Service Implementation - Where gRPC Magic Happens!</p> <p>This module contains the main business logic for the BasicService, implementing a delightfully interactive gRPC service that can: - Greet you like a friendly neighbor \ud83d\udc4b - Chat with you using an AI therapist (Eliza) \ud83e\udde0 - Run background tasks like a multitasking wizard \u26a1</p> <p>The service demonstrates various gRPC patterns including unary calls, streaming, and background task orchestration with proper error handling and CloudEvents.</p> <p>Author: The gRPC Service Squad \ud83e\uddb8\u200d\u2640\ufe0f\ud83e\uddb8\u200d\u2642\ufe0f</p>"},{"location":"reference/services.basic_service/#services.basic_service-classes","title":"Classes","text":""},{"location":"reference/services.basic_service/#services.basic_service.BasicServiceImpl","title":"BasicServiceImpl","text":"<p>               Bases: <code>BasicServiceServicer</code></p> <p>\ud83c\udf1f The star of the show - BasicService implementation!</p> <p>This class implements the BasicService gRPC interface, providing three main functionalities wrapped in CloudEvents for that extra enterprise sparkle \u2728:</p> <ol> <li>Hello - A simple greeting service that says hello back</li> <li>Talk - A streaming chat service powered by the Eliza chatbot</li> <li>Background - Parallel task execution with real-time progress streaming</li> </ol> <p>Each method demonstrates different gRPC patterns: - Unary RPC (Hello) - Bidirectional streaming (Talk) - Server streaming with background tasks (Background)</p> Source code in <code>services/basic_service.py</code> <pre><code>class BasicServiceImpl(basic_pb2_grpc.BasicServiceServicer):\n    \"\"\"\n    \ud83c\udf1f The star of the show - BasicService implementation!\n\n    This class implements the BasicService gRPC interface, providing three main\n    functionalities wrapped in CloudEvents for that extra enterprise sparkle \u2728:\n\n    1. Hello - A simple greeting service that says hello back\n    2. Talk - A streaming chat service powered by the Eliza chatbot\n    3. Background - Parallel task execution with real-time progress streaming\n\n    Each method demonstrates different gRPC patterns:\n    - Unary RPC (Hello)\n    - Bidirectional streaming (Talk)\n    - Server streaming with background tasks (Background)\n    \"\"\"\n\n    async def Hello(self, request: service_pb2.HelloRequest, context: grpc.aio.ServicerContext) -&gt; service_pb2.HelloResponse:\n        \"\"\"\n        \ud83d\udc4b Say hello in the most elaborate way possible!\n\n        Takes a simple message and wraps it in a CloudEvent because even\n        greetings deserve enterprise-grade packaging. This demonstrates\n        the basic unary RPC pattern with CloudEvents integration.\n\n        Args:\n            request (service_pb2.HelloRequest): The incoming hello request with a message\n            context (grpc.aio.ServicerContext): gRPC service context (standard gRPC magic)\n\n        Returns:\n            service_pb2.HelloResponse: A CloudEvent-wrapped greeting response\n\n        Example:\n            Input: HelloRequest(message=\"World\")\n            Output: HelloResponse containing CloudEvent with \"Hello, World\"\n\n        Note:\n            Each response gets a unique UUID and timestamp because we're fancy like that! \ud83d\udc85\n        \"\"\"\n        # Create the actual greeting event payload\n        event = service_pb2.HelloResponseEvent(\n            greeting=f\"Hello, {request.message}\"\n        )\n\n        # Pack it into a protobuf Any message (because flexibility is key)\n        any_payload = Any()\n        any_payload.Pack(event)\n\n        # Create a timestamp for when this magical moment happened\n        timestamp = Timestamp()\n        timestamp.FromDatetime(dt.datetime.now(dt.timezone.utc))\n\n        # Wrap everything in a fancy CloudEvent envelope \ud83d\udce7\n        cloudevent = CloudEvent(\n            id=str(uuid.uuid4()),  # Every event is special and unique\n            spec_version=\"v1.0\",\n            source=\"basic.v1.BasicService/Hello\",\n            type=service_pb2.DESCRIPTOR.message_types_by_name['HelloResponse'].full_name,\n            attributes={\n                \"time\": CloudEvent.CloudEventAttributeValue(ce_timestamp=timestamp),\n            },\n            proto_data=any_payload,\n        )\n\n        return service_pb2.HelloResponse(cloud_event=cloudevent)\n\n    #     async def Talk(self, request_iterator: AsyncIterator[service_pb2.TalkRequest], context: grpc.aio.ServicerContext) -&gt; AsyncIterator[service_pb2.TalkResponse]:\n\n\n    async def Talk(self, request_iterator, context: grpc.aio.ServicerContext):\n        \"\"\"\n        \ud83e\udde0 Have a therapeutic chat with our resident AI psychologist!\n\n        This streaming method connects you with Eliza, the classic chatbot\n        therapist. Send messages and receive thoughtful (or seemingly thoughtful)\n        responses in real-time. It's like having a conversation with a very\n        patient, if somewhat repetitive, therapist.\n\n        Args:\n            request_iterator: Async iterator of TalkRequest messages from the client\n            context (grpc.aio.ServicerContext): gRPC service context for streaming magic\n\n        Yields:\n            service_pb2.TalkResponse: Streaming responses from our AI therapist\n\n        Features:\n            - Bidirectional streaming (talk and listen simultaneously)\n            - Built-in Eliza chatbot for therapeutic conversations\n            - Debug logging for conversation tracking\n            - Handles client disconnection gracefully\n\n        Example Conversation:\n            Client: \"I feel sad today\"\n            Eliza: \"I am sorry to hear that you are sad.\"\n            Client: \"Why do I feel this way?\"\n            Eliza: \"Why do you say that?\"\n\n        Note:\n            Eliza might seem repetitive, but that's part of her charm! She's been\n            doing this since 1966, so she's got experience. \ud83d\udc75\n        \"\"\"\n        # Create our therapeutic AI companion\n        eliza = Eliza()\n\n        # Process each incoming message from the client\n        async for message_request in request_iterator:\n            # Get Eliza's wise response\n            eliza_reply = eliza.reply(message_request.message)\n\n            # Log the conversation for debugging (and entertainment)\n            logging.debug(\"Talk in=%r -&gt; out=%r goodbye=%s\",\n                         message_request.message, eliza_reply.text, eliza_reply.goodbye)\n\n            # Stream back the response\n            yield service_pb2.TalkResponse(answer=eliza_reply.text)\n\n    async def Background(self, request: service_pb2.BackgroundRequest, context: grpc.aio.ServicerContext):\n        \"\"\"\n        \u26a1 The multitasking maestro - run multiple background tasks in parallel!\n\n        This method demonstrates advanced async patterns by spinning up multiple\n        background workers that simulate calling various services. It provides\n        real-time progress updates via server streaming and handles errors gracefully.\n\n        Perfect for demonstrating:\n        - Parallel task execution with asyncio\n        - Server-side streaming with progress updates\n        - Error handling and recovery in distributed systems\n        - Task cancellation on client disconnect\n\n        Args:\n            request (service_pb2.BackgroundRequest): Configuration for background tasks\n            context (grpc.aio.ServicerContext): gRPC context for streaming responses\n\n        Yields:\n            service_pb2.BackgroundResponse: Stream of progress updates wrapped in CloudEvents\n\n        Request Parameters:\n            - processes (int): Number of parallel workers to spawn (defaults to 1)\n\n        Streaming Behavior:\n            1. Initial STATE_PROCESS response with empty results\n            2. Updated STATE_PROCESS responses after each task completion\n            3. Final STATE_COMPLETE response with all results\n\n        Error Handling:\n            - Individual task failures are captured and included as error responses\n            - Client cancellation properly stops all background workers\n            - Transport errors cancel all tasks and propagate the error\n\n        Example:\n            Request: BackgroundRequest(processes=3)\n            Stream: [Initial empty, Progress 1/3, Progress 2/3, Progress 3/3, Final complete]\n\n        Note:\n            Workers simulate calling random services (REST, gRPC, etc.) with realistic delays.\n            It's like having a team of very dedicated, if imaginary, service callers! \ud83c\udfc3\u200d\u2640\ufe0f\ud83c\udfc3\u200d\u2642\ufe0f\n        \"\"\"\n        # Create our service simulation helper\n        some = Some()\n\n        # Ensure we have at least one process (because zero workers accomplish nothing)\n        process_count = request.processes or 1\n        if process_count &lt;= 0:\n            process_count = 1\n\n        # Record when this epic background operation began\n        started_at = dt.datetime.now(dt.timezone.utc)\n\n        # Queue for collecting worker results as they complete\n        result_queue: asyncio.Queue = asyncio.Queue()\n        worker_tasks = []\n\n        async def background_worker(worker_id: int):\n            \"\"\"\n            \ud83d\udd27 Individual background worker that simulates service calls.\n\n            Each worker pretends to call a random service type (REST, gRPC, etc.)\n            and takes a realistic amount of time to complete. Results are queued\n            for the main streaming loop to process.\n\n            Args:\n                worker_id (int): Unique identifier for this worker\n\n            Note:\n                Uses asyncio.to_thread() to run the blocking fake_service_response\n                in a thread pool, keeping our async event loop happy! \ud83d\ude0a\n            \"\"\"\n            try:\n                # Pick a random protocol because variety is the spice of life\n                protocol = random.choice([\n                    \"rest\", \"grpc\", \"rpc\", \"ws\", \"mqtt\", \"amqp\",\n                    \"graphql\", \"sql\", \"file\"\n                ])\n\n                # Simulate the service call (runs in thread to avoid blocking)\n                service_result = await asyncio.to_thread(\n                    some.fake_service_response,\n                    f\"service-{worker_id}\",\n                    protocol=protocol\n                )\n\n                # Deliver the good news\n                await result_queue.put(service_result)\n\n            except Exception as error:\n                # Even workers have bad days - log and queue the error\n                logging.exception(\"Background worker %s failed\", worker_id)\n                await result_queue.put(error)\n\n        # Launch all our hardworking background processes\n        for worker_num in range(1, process_count + 1):\n            task = asyncio.create_task(background_worker(worker_num))\n            worker_tasks.append(task)\n\n        # Start the streaming show!\n        try:\n            # Send initial status: \"We've started, but nothing's done yet\"\n            yield some.build_background_response(\n                state=service_pb2.State.STATE_PROCESS,\n                started_at=started_at,\n                completed_at=None,\n                responses=[]\n            )\n\n            # Track completion progress\n            remaining_tasks = process_count\n            completed_responses = []\n\n            # Process results as workers complete their tasks\n            while remaining_tasks &gt; 0:\n                # Wait for the next worker to finish (or fail)\n                completed_item = await result_queue.get()\n\n                if isinstance(completed_item, Exception):\n                    # Handle worker failures gracefully by creating error responses\n                    error_response = service_pb2.SomeServiceResponse(\n                        id=str(uuid.uuid4()),\n                        name=\"background-error\",\n                        version=\"v1\",\n                        data=service_pb2.SomeServiceData(\n                            value=str(completed_item),\n                            type=\"error\",\n                        ),\n                    )\n                    completed_responses.append(error_response)\n                else:\n                    # Success! Add the real response\n                    completed_responses.append(completed_item)\n\n                remaining_tasks -= 1\n\n                # Send progress update with current results\n                yield some.build_background_response(\n                    state=service_pb2.State.STATE_PROCESS,\n                    started_at=started_at,\n                    completed_at=None,\n                    responses=list(completed_responses)  # Send a snapshot\n                )\n\n            # Wait for all tasks to fully complete (cleanup)\n            await asyncio.gather(*worker_tasks, return_exceptions=True)\n\n            # Send final completion status with all results\n            yield some.build_background_response(\n                state=service_pb2.State.STATE_COMPLETE,\n                started_at=started_at,\n                completed_at=dt.datetime.now(dt.timezone.utc),\n                responses=completed_responses\n            )\n\n        except asyncio.CancelledError:\n            # Client said \"never mind\" - clean up our workers\n            logging.info(\"Background operation cancelled by client\")\n            for task in worker_tasks:\n                task.cancel()\n            raise\n\n        except grpc.aio.AioRpcError as rpc_error:\n            # Network or transport issues - abort everything\n            for task in worker_tasks:\n                task.cancel()\n            logging.warning(\"Background stream aborted: %s (%s)\",\n                          rpc_error.code(), rpc_error.details())\n            raise\n\n        except Exception:\n            # Any other unexpected error - cancel tasks and re-raise\n            for task in worker_tasks:\n                task.cancel()\n            logging.exception(\"Background stream encountered unexpected error\")\n            raise\n</code></pre>"},{"location":"reference/services.basic_service/#services.basic_service.BasicServiceImpl-functions","title":"Functions","text":""},{"location":"reference/services.basic_service/#services.basic_service.BasicServiceImpl.Background","title":"Background  <code>async</code>","text":"<pre><code>Background(request, context)\n</code></pre> <p>\u26a1 The multitasking maestro - run multiple background tasks in parallel!</p> <p>This method demonstrates advanced async patterns by spinning up multiple background workers that simulate calling various services. It provides real-time progress updates via server streaming and handles errors gracefully.</p> <p>Perfect for demonstrating: - Parallel task execution with asyncio - Server-side streaming with progress updates - Error handling and recovery in distributed systems - Task cancellation on client disconnect</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>BackgroundRequest</code> <p>Configuration for background tasks</p> required <code>context</code> <code>ServicerContext</code> <p>gRPC context for streaming responses</p> required <p>Yields:</p> Type Description <p>service_pb2.BackgroundResponse: Stream of progress updates wrapped in CloudEvents</p> Request Parameters <ul> <li>processes (int): Number of parallel workers to spawn (defaults to 1)</li> </ul> Streaming Behavior <ol> <li>Initial STATE_PROCESS response with empty results</li> <li>Updated STATE_PROCESS responses after each task completion</li> <li>Final STATE_COMPLETE response with all results</li> </ol> Error Handling <ul> <li>Individual task failures are captured and included as error responses</li> <li>Client cancellation properly stops all background workers</li> <li>Transport errors cancel all tasks and propagate the error</li> </ul> Example <p>Request: BackgroundRequest(processes=3) Stream: [Initial empty, Progress 1/3, Progress 2/3, Progress 3/3, Final complete]</p> Note <p>Workers simulate calling random services (REST, gRPC, etc.) with realistic delays. It's like having a team of very dedicated, if imaginary, service callers! \ud83c\udfc3\u200d\u2640\ufe0f\ud83c\udfc3\u200d\u2642\ufe0f</p> Source code in <code>services/basic_service.py</code> <pre><code>async def Background(self, request: service_pb2.BackgroundRequest, context: grpc.aio.ServicerContext):\n    \"\"\"\n    \u26a1 The multitasking maestro - run multiple background tasks in parallel!\n\n    This method demonstrates advanced async patterns by spinning up multiple\n    background workers that simulate calling various services. It provides\n    real-time progress updates via server streaming and handles errors gracefully.\n\n    Perfect for demonstrating:\n    - Parallel task execution with asyncio\n    - Server-side streaming with progress updates\n    - Error handling and recovery in distributed systems\n    - Task cancellation on client disconnect\n\n    Args:\n        request (service_pb2.BackgroundRequest): Configuration for background tasks\n        context (grpc.aio.ServicerContext): gRPC context for streaming responses\n\n    Yields:\n        service_pb2.BackgroundResponse: Stream of progress updates wrapped in CloudEvents\n\n    Request Parameters:\n        - processes (int): Number of parallel workers to spawn (defaults to 1)\n\n    Streaming Behavior:\n        1. Initial STATE_PROCESS response with empty results\n        2. Updated STATE_PROCESS responses after each task completion\n        3. Final STATE_COMPLETE response with all results\n\n    Error Handling:\n        - Individual task failures are captured and included as error responses\n        - Client cancellation properly stops all background workers\n        - Transport errors cancel all tasks and propagate the error\n\n    Example:\n        Request: BackgroundRequest(processes=3)\n        Stream: [Initial empty, Progress 1/3, Progress 2/3, Progress 3/3, Final complete]\n\n    Note:\n        Workers simulate calling random services (REST, gRPC, etc.) with realistic delays.\n        It's like having a team of very dedicated, if imaginary, service callers! \ud83c\udfc3\u200d\u2640\ufe0f\ud83c\udfc3\u200d\u2642\ufe0f\n    \"\"\"\n    # Create our service simulation helper\n    some = Some()\n\n    # Ensure we have at least one process (because zero workers accomplish nothing)\n    process_count = request.processes or 1\n    if process_count &lt;= 0:\n        process_count = 1\n\n    # Record when this epic background operation began\n    started_at = dt.datetime.now(dt.timezone.utc)\n\n    # Queue for collecting worker results as they complete\n    result_queue: asyncio.Queue = asyncio.Queue()\n    worker_tasks = []\n\n    async def background_worker(worker_id: int):\n        \"\"\"\n        \ud83d\udd27 Individual background worker that simulates service calls.\n\n        Each worker pretends to call a random service type (REST, gRPC, etc.)\n        and takes a realistic amount of time to complete. Results are queued\n        for the main streaming loop to process.\n\n        Args:\n            worker_id (int): Unique identifier for this worker\n\n        Note:\n            Uses asyncio.to_thread() to run the blocking fake_service_response\n            in a thread pool, keeping our async event loop happy! \ud83d\ude0a\n        \"\"\"\n        try:\n            # Pick a random protocol because variety is the spice of life\n            protocol = random.choice([\n                \"rest\", \"grpc\", \"rpc\", \"ws\", \"mqtt\", \"amqp\",\n                \"graphql\", \"sql\", \"file\"\n            ])\n\n            # Simulate the service call (runs in thread to avoid blocking)\n            service_result = await asyncio.to_thread(\n                some.fake_service_response,\n                f\"service-{worker_id}\",\n                protocol=protocol\n            )\n\n            # Deliver the good news\n            await result_queue.put(service_result)\n\n        except Exception as error:\n            # Even workers have bad days - log and queue the error\n            logging.exception(\"Background worker %s failed\", worker_id)\n            await result_queue.put(error)\n\n    # Launch all our hardworking background processes\n    for worker_num in range(1, process_count + 1):\n        task = asyncio.create_task(background_worker(worker_num))\n        worker_tasks.append(task)\n\n    # Start the streaming show!\n    try:\n        # Send initial status: \"We've started, but nothing's done yet\"\n        yield some.build_background_response(\n            state=service_pb2.State.STATE_PROCESS,\n            started_at=started_at,\n            completed_at=None,\n            responses=[]\n        )\n\n        # Track completion progress\n        remaining_tasks = process_count\n        completed_responses = []\n\n        # Process results as workers complete their tasks\n        while remaining_tasks &gt; 0:\n            # Wait for the next worker to finish (or fail)\n            completed_item = await result_queue.get()\n\n            if isinstance(completed_item, Exception):\n                # Handle worker failures gracefully by creating error responses\n                error_response = service_pb2.SomeServiceResponse(\n                    id=str(uuid.uuid4()),\n                    name=\"background-error\",\n                    version=\"v1\",\n                    data=service_pb2.SomeServiceData(\n                        value=str(completed_item),\n                        type=\"error\",\n                    ),\n                )\n                completed_responses.append(error_response)\n            else:\n                # Success! Add the real response\n                completed_responses.append(completed_item)\n\n            remaining_tasks -= 1\n\n            # Send progress update with current results\n            yield some.build_background_response(\n                state=service_pb2.State.STATE_PROCESS,\n                started_at=started_at,\n                completed_at=None,\n                responses=list(completed_responses)  # Send a snapshot\n            )\n\n        # Wait for all tasks to fully complete (cleanup)\n        await asyncio.gather(*worker_tasks, return_exceptions=True)\n\n        # Send final completion status with all results\n        yield some.build_background_response(\n            state=service_pb2.State.STATE_COMPLETE,\n            started_at=started_at,\n            completed_at=dt.datetime.now(dt.timezone.utc),\n            responses=completed_responses\n        )\n\n    except asyncio.CancelledError:\n        # Client said \"never mind\" - clean up our workers\n        logging.info(\"Background operation cancelled by client\")\n        for task in worker_tasks:\n            task.cancel()\n        raise\n\n    except grpc.aio.AioRpcError as rpc_error:\n        # Network or transport issues - abort everything\n        for task in worker_tasks:\n            task.cancel()\n        logging.warning(\"Background stream aborted: %s (%s)\",\n                      rpc_error.code(), rpc_error.details())\n        raise\n\n    except Exception:\n        # Any other unexpected error - cancel tasks and re-raise\n        for task in worker_tasks:\n            task.cancel()\n        logging.exception(\"Background stream encountered unexpected error\")\n        raise\n</code></pre>"},{"location":"reference/services.basic_service/#services.basic_service.BasicServiceImpl.Hello","title":"Hello  <code>async</code>","text":"<pre><code>Hello(request, context)\n</code></pre> <p>\ud83d\udc4b Say hello in the most elaborate way possible!</p> <p>Takes a simple message and wraps it in a CloudEvent because even greetings deserve enterprise-grade packaging. This demonstrates the basic unary RPC pattern with CloudEvents integration.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>HelloRequest</code> <p>The incoming hello request with a message</p> required <code>context</code> <code>ServicerContext</code> <p>gRPC service context (standard gRPC magic)</p> required <p>Returns:</p> Type Description <code>HelloResponse</code> <p>service_pb2.HelloResponse: A CloudEvent-wrapped greeting response</p> Example <p>Input: HelloRequest(message=\"World\") Output: HelloResponse containing CloudEvent with \"Hello, World\"</p> Note <p>Each response gets a unique UUID and timestamp because we're fancy like that! \ud83d\udc85</p> Source code in <code>services/basic_service.py</code> <pre><code>async def Hello(self, request: service_pb2.HelloRequest, context: grpc.aio.ServicerContext) -&gt; service_pb2.HelloResponse:\n    \"\"\"\n    \ud83d\udc4b Say hello in the most elaborate way possible!\n\n    Takes a simple message and wraps it in a CloudEvent because even\n    greetings deserve enterprise-grade packaging. This demonstrates\n    the basic unary RPC pattern with CloudEvents integration.\n\n    Args:\n        request (service_pb2.HelloRequest): The incoming hello request with a message\n        context (grpc.aio.ServicerContext): gRPC service context (standard gRPC magic)\n\n    Returns:\n        service_pb2.HelloResponse: A CloudEvent-wrapped greeting response\n\n    Example:\n        Input: HelloRequest(message=\"World\")\n        Output: HelloResponse containing CloudEvent with \"Hello, World\"\n\n    Note:\n        Each response gets a unique UUID and timestamp because we're fancy like that! \ud83d\udc85\n    \"\"\"\n    # Create the actual greeting event payload\n    event = service_pb2.HelloResponseEvent(\n        greeting=f\"Hello, {request.message}\"\n    )\n\n    # Pack it into a protobuf Any message (because flexibility is key)\n    any_payload = Any()\n    any_payload.Pack(event)\n\n    # Create a timestamp for when this magical moment happened\n    timestamp = Timestamp()\n    timestamp.FromDatetime(dt.datetime.now(dt.timezone.utc))\n\n    # Wrap everything in a fancy CloudEvent envelope \ud83d\udce7\n    cloudevent = CloudEvent(\n        id=str(uuid.uuid4()),  # Every event is special and unique\n        spec_version=\"v1.0\",\n        source=\"basic.v1.BasicService/Hello\",\n        type=service_pb2.DESCRIPTOR.message_types_by_name['HelloResponse'].full_name,\n        attributes={\n            \"time\": CloudEvent.CloudEventAttributeValue(ce_timestamp=timestamp),\n        },\n        proto_data=any_payload,\n    )\n\n    return service_pb2.HelloResponse(cloud_event=cloudevent)\n</code></pre>"},{"location":"reference/services.basic_service/#services.basic_service.BasicServiceImpl.Talk","title":"Talk  <code>async</code>","text":"<pre><code>Talk(request_iterator, context)\n</code></pre> <p>\ud83e\udde0 Have a therapeutic chat with our resident AI psychologist!</p> <p>This streaming method connects you with Eliza, the classic chatbot therapist. Send messages and receive thoughtful (or seemingly thoughtful) responses in real-time. It's like having a conversation with a very patient, if somewhat repetitive, therapist.</p> <p>Parameters:</p> Name Type Description Default <code>request_iterator</code> <p>Async iterator of TalkRequest messages from the client</p> required <code>context</code> <code>ServicerContext</code> <p>gRPC service context for streaming magic</p> required <p>Yields:</p> Type Description <p>service_pb2.TalkResponse: Streaming responses from our AI therapist</p> Features <ul> <li>Bidirectional streaming (talk and listen simultaneously)</li> <li>Built-in Eliza chatbot for therapeutic conversations</li> <li>Debug logging for conversation tracking</li> <li>Handles client disconnection gracefully</li> </ul> Example Conversation <p>Client: \"I feel sad today\" Eliza: \"I am sorry to hear that you are sad.\" Client: \"Why do I feel this way?\" Eliza: \"Why do you say that?\"</p> Note <p>Eliza might seem repetitive, but that's part of her charm! She's been doing this since 1966, so she's got experience. \ud83d\udc75</p> Source code in <code>services/basic_service.py</code> <pre><code>async def Talk(self, request_iterator, context: grpc.aio.ServicerContext):\n    \"\"\"\n    \ud83e\udde0 Have a therapeutic chat with our resident AI psychologist!\n\n    This streaming method connects you with Eliza, the classic chatbot\n    therapist. Send messages and receive thoughtful (or seemingly thoughtful)\n    responses in real-time. It's like having a conversation with a very\n    patient, if somewhat repetitive, therapist.\n\n    Args:\n        request_iterator: Async iterator of TalkRequest messages from the client\n        context (grpc.aio.ServicerContext): gRPC service context for streaming magic\n\n    Yields:\n        service_pb2.TalkResponse: Streaming responses from our AI therapist\n\n    Features:\n        - Bidirectional streaming (talk and listen simultaneously)\n        - Built-in Eliza chatbot for therapeutic conversations\n        - Debug logging for conversation tracking\n        - Handles client disconnection gracefully\n\n    Example Conversation:\n        Client: \"I feel sad today\"\n        Eliza: \"I am sorry to hear that you are sad.\"\n        Client: \"Why do I feel this way?\"\n        Eliza: \"Why do you say that?\"\n\n    Note:\n        Eliza might seem repetitive, but that's part of her charm! She's been\n        doing this since 1966, so she's got experience. \ud83d\udc75\n    \"\"\"\n    # Create our therapeutic AI companion\n    eliza = Eliza()\n\n    # Process each incoming message from the client\n    async for message_request in request_iterator:\n        # Get Eliza's wise response\n        eliza_reply = eliza.reply(message_request.message)\n\n        # Log the conversation for debugging (and entertainment)\n        logging.debug(\"Talk in=%r -&gt; out=%r goodbye=%s\",\n                     message_request.message, eliza_reply.text, eliza_reply.goodbye)\n\n        # Stream back the response\n        yield service_pb2.TalkResponse(answer=eliza_reply.text)\n</code></pre>"},{"location":"reference/utils.eliza/","title":"Eliza Chatbot","text":"<p>Classic ELIZA therapeutic chatbot implementation</p>"},{"location":"reference/utils.eliza/#utils.eliza","title":"eliza","text":"<p>\ud83e\udde0 Eliza - Your Friendly Neighborhood AI Therapist</p> <p>Welcome to the classic Eliza chatbot implementation! This module provides a Python version of the famous ELIZA program, originally created by Joseph Weizenbaum at MIT in 1964-1966. Eliza simulates a Rogerian psychotherapist using pattern matching and clever reflections.</p> <p>Why Eliza? Because sometimes you need someone to listen, even if that someone is just a bunch of regular expressions pretending to care! \ud83e\udd16\ud83d\udc95</p> <p>Features: - Pattern-based conversation simulation - Pronoun reflection (\"I am sad\" -&gt; \"How long have you been sad?\") - Goodbye detection for natural conversation endings - Randomized responses to keep things interesting - Classic therapeutic responses that sound surprisingly human</p> <p>Author: The AI Therapy Department \ud83d\udecb\ufe0f</p>"},{"location":"reference/utils.eliza/#utils.eliza-classes","title":"Classes","text":""},{"location":"reference/utils.eliza/#utils.eliza.Eliza","title":"Eliza","text":"<p>\ud83e\udde0 The classic Eliza chatbot - Your digital Rogerian therapist!</p> <p>Eliza uses pattern matching and reflection techniques to simulate understanding and empathy. She's been helping people feel heard since 1966, making her one of the most experienced therapists in the business (even if she's not technically real).</p> <p>How Eliza Works: 1. Matches your input against predefined patterns 2. Reflects pronouns back at you (\"I am\" becomes \"you are\") 3. Responds with contextually appropriate therapeutic responses 4. Falls back to generic responses when confused 5. Recognizes goodbye patterns to end conversations gracefully</p> <p>Therapeutic Specialties: - Active listening (pattern matching style!) - Pronoun reflection therapy - Question deflection techniques - Family inquiry methods - Emotional validation responses</p> Example Session <p>You: \"I am feeling sad today\" Eliza: \"Did you come to me because you are feeling sad today?\" You: \"My mother never understood me\" Eliza: \"Tell me more about your family.\" You: \"Goodbye\" Eliza: \"Thank you for talking with me.\"</p> Source code in <code>utils/eliza.py</code> <pre><code>class Eliza:\n    \"\"\"\n    \ud83e\udde0 The classic Eliza chatbot - Your digital Rogerian therapist!\n\n    Eliza uses pattern matching and reflection techniques to simulate\n    understanding and empathy. She's been helping people feel heard\n    since 1966, making her one of the most experienced therapists\n    in the business (even if she's not technically real).\n\n    How Eliza Works:\n    1. Matches your input against predefined patterns\n    2. Reflects pronouns back at you (\"I am\" becomes \"you are\")\n    3. Responds with contextually appropriate therapeutic responses\n    4. Falls back to generic responses when confused\n    5. Recognizes goodbye patterns to end conversations gracefully\n\n    Therapeutic Specialties:\n    - Active listening (pattern matching style!)\n    - Pronoun reflection therapy\n    - Question deflection techniques\n    - Family inquiry methods\n    - Emotional validation responses\n\n    Example Session:\n        You: \"I am feeling sad today\"\n        Eliza: \"Did you come to me because you are feeling sad today?\"\n        You: \"My mother never understood me\"\n        Eliza: \"Tell me more about your family.\"\n        You: \"Goodbye\"\n        Eliza: \"Thank you for talking with me.\"\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        \ud83c\udfad Initialize Eliza with her therapeutic training!\n\n        Sets up all the patterns, responses, and reflection rules\n        that make Eliza seem surprisingly human. Think of this as\n        her going through therapy school, but really quickly.\n        \"\"\"\n\n        # \ud83d\udd04 Reflection dictionary for pronoun swapping\n        # This is the secret sauce that makes \"I am sad\" become \"you are sad\"\n        self.reflections = {\n            \"am\": \"are\",\n            \"was\": \"were\",\n            \"i\": \"you\",\n            \"i'd\": \"you would\",\n            \"i've\": \"you have\",\n            \"i'll\": \"you will\",\n            \"my\": \"your\",\n            \"are\": \"am\",\n            \"you've\": \"I have\",\n            \"you'll\": \"I will\",\n            \"your\": \"my\",\n            \"yours\": \"mine\",\n            \"you\": \"I\",\n            \"me\": \"you\",\n            \"myself\": \"yourself\",\n            \"yourself\": \"myself\"\n        }\n\n        # \ud83d\udc4b Goodbye patterns - Because every therapy session must end\n        self.goodbye_patterns = [\n            (r'.*(bye|goodbye|see you|farewell|quit|exit|leave).*', [\n                \"Thank you for talking with me.\",\n                \"Good-bye. This was really a nice talk.\",\n                \"Thank you, that will be $150. Have a good day!\",  # \ud83d\udcb0 Even AI therapists have bills!\n                \"Good-bye. I hope I have helped you.\",\n                \"This was a nice session. Good-bye.\"\n            ])\n        ]\n\n        # \ud83c\udfaf Pattern-response pairs - Eliza's therapeutic toolkit\n        # Each tuple contains (regex_pattern, list_of_possible_responses)\n        self.patterns = [\n            # Apology handling - We don't need no stinkin' apologies!\n            (r'.*\\bsorry\\b.*', [\n                \"Please don't apologize.\",\n                \"Apologies are not necessary.\",\n                \"What feelings do you have when you apologize?\"\n            ]),\n\n            # Memory exploration - Let's dig into those memories\n            (r'.*\\bremember\\b (.*)', [\n                \"Do you often think of {0}?\",\n                \"Does thinking of {0} bring anything else to mind?\",\n                \"What else do you remember?\",\n                \"Why do you remember {0} just now?\"\n            ]),\n\n            # Dream analysis - Because dreams are windows to the soul, maybe\n            (r'.*\\bdream\\b.*', [\n                \"What does that dream suggest to you?\",\n                \"Do you dream often?\",\n                \"What persons appear in your dreams?\",\n                \"Are you disturbed by your dreams?\"\n            ]),\n\n            # Family therapy - It always comes back to family, doesn't it?\n            (r'.*(mother|mom|father|dad|parents|family).*', [\n                \"Tell me more about your family.\",\n                \"Who else in your family {0}?\",\n                \"Your {0}?\",\n                \"What else comes to mind when you think of your {0}?\"\n            ]),\n\n            # Emotional support - Sad feelings need validation\n            (r'.*\\b(sad|unhappy|depressed|upset)\\b.*', [\n                \"I am sorry to hear that you are {0}.\",\n                \"Do you think coming here will help you not to be {0}?\",\n                \"I'm sure it's not pleasant to be {0}.\",\n                \"Can you explain what made you {0}?\"\n            ]),\n\n            # Positive emotions - Let's explore that happiness!\n            (r'.*\\b(happy|elated|glad|better)\\b.*', [\n                \"How have I helped you to be {0}?\",\n                \"Has your treatment made you {0}?\",\n                \"What makes you {0} just now?\",\n                \"Can you explain why you are suddenly {0}?\"\n            ]),\n\n            # Belief exploration - Question those thoughts!\n            (r'.*\\b(believe|think)\\b (.*)', [\n                \"Do you really think so?\",\n                \"But you are not sure you {0}.\",\n                \"Do you really doubt you {0}?\"\n            ]),\n\n            # Affirmative responses - When they say yes\n            (r'.*(yes|yeah|yep).*', [\n                \"You seem quite positive.\",\n                \"You are sure?\",\n                \"I see.\",\n                \"I understand.\"\n            ]),\n\n            # Negative responses - When they say no\n            (r'.*(no|nope|nah).*', [\n                \"Are you saying 'No' just to be negative?\",\n                \"You are being a bit negative.\",\n                \"Why not?\",\n                \"Why 'No'?\"\n            ]),\n\n            # Self-identification - \"I am\" statements get special treatment\n            (r'.*\\bi am (.*)', [\n                \"Did you come to me because you are {0}?\",\n                \"How long have you been {0}?\",\n                \"Do you believe it is normal to be {0}?\",\n                \"Do you enjoy being {0}?\"\n            ]),\n\n            # General self-reference - Deflect back to them\n            (r'.*\\bi (.*)', [\n                \"We should be discussing you, not me.\",\n                \"Why do you say that?\",\n                \"I see.\",\n                \"And what does that tell you?\",\n                \"How does that make you feel?\"\n            ]),\n\n            # Direct statements about Eliza - Turn it around\n            (r'.*\\byou are (.*)', [\n                \"Why are you interested in whether I am {0} or not?\",\n                \"Would you prefer if I were not {0}?\",\n                \"Perhaps I am {0} in your fantasies.\",\n                \"Do you sometimes think I am {0}?\"\n            ]),\n\n            # General \"you\" statements - Deflect to patient\n            (r'.*\\byou (.*)', [\n                \"We should be discussing you, not me.\",\n                \"Oh, I {0}?\",\n                \"You're not really talking about me, are you?\",\n                \"What makes you think I {0}?\"\n            ])\n        ]\n\n        # \ud83e\udd37\u200d\u2640\ufe0f Default responses - When all else fails, be vague!\n        # These are the therapy equivalent of \"turn it off and on again\"\n        self.default_responses = [\n            \"Please tell me more.\",\n            \"Let's change focus a bit... Tell me about your family.\",\n            \"Can you elaborate on that?\",\n            \"Why do you say that?\",\n            \"I see.\",\n            \"Very interesting.\",\n            \"I see.  And what does that tell you?\",\n            \"How does that make you feel?\",\n            \"Do you feel strongly about discussing such things?\"\n        ]\n\n    def __reflect(self, text_fragment: str) -&gt; str:\n        \"\"\"\n        \ud83e\ude9e The magic mirror - reflect pronouns back to the user.\n\n        This is where the therapeutic magic happens! Eliza takes what you\n        said and reflects it back by swapping pronouns and perspective.\n        \"I am sad\" becomes \"you are sad\", creating the illusion that\n        she's really listening and understanding.\n\n        Args:\n            text_fragment (str): The text to reflect back\n\n        Returns:\n            str: The reflected text with pronouns swapped\n\n        Example:\n            &gt;&gt;&gt; eliza = Eliza()\n            &gt;&gt;&gt; eliza._Eliza__reflect(\"I am feeling happy\")\n            \"you are feeling happy\"\n\n        Note:\n            This method preserves punctuation while doing the reflection,\n            because even AI therapists should have good grammar! \u2728\n        \"\"\"\n        # Split into individual words for processing\n        word_tokens = text_fragment.lower().split()\n        reflected_words = []\n\n        for word in word_tokens:\n            # Separate the actual word from any punctuation\n            clean_word = re.sub(r'[^\\w]', '', word)\n            punctuation = word[len(clean_word):]\n\n            # Apply reflection if we know how to transform this word\n            if clean_word in self.reflections:\n                reflected_word = self.reflections[clean_word] + punctuation\n            else:\n                reflected_word = word\n\n            reflected_words.append(reflected_word)\n\n        return ' '.join(reflected_words)\n\n    def reply(self, user_message: str) -&gt; Reply:\n        \"\"\"\n        \ud83d\udcad Generate a therapeutic response to the user's message.\n\n        This is Eliza's main brain function! She analyzes what you said,\n        tries to match it against her patterns, and responds with something\n        that sounds like she actually cares (spoiler: she doesn't, but\n        she's very good at pretending).\n\n        Process:\n        1. Check if it's a goodbye message first\n        2. Try to match against therapeutic patterns\n        3. If pattern matches and has groups, reflect them back\n        4. If no patterns match, use a generic response\n        5. Add some randomness to keep things interesting\n\n        Args:\n            user_message (str): What the human said to Eliza\n\n        Returns:\n            Reply: Eliza's thoughtful (or generic) response\n\n        Examples:\n            &gt;&gt;&gt; eliza = Eliza()\n            &gt;&gt;&gt; reply = eliza.reply(\"I am feeling sad\")\n            &gt;&gt;&gt; reply.text\n            \"Did you come to me because you are feeling sad?\"\n\n            &gt;&gt;&gt; reply = eliza.reply(\"goodbye\")\n            &gt;&gt;&gt; reply.goodbye\n            True\n\n        Note:\n            Empty messages get a gentle nudge to actually say something.\n            Even AI therapists need something to work with! \ud83e\udd37\u200d\u2640\ufe0f\n        \"\"\"\n        # Handle empty or whitespace-only input\n        if not user_message.strip():\n            return Reply(\"Please say something.\")\n\n        # Convert to lowercase for easier pattern matching\n        lowercase_input = user_message.lower()\n\n        # \ud83d\udc4b First priority: Check for goodbye patterns\n        for goodbye_pattern, goodbye_responses in self.goodbye_patterns:\n            if re.match(goodbye_pattern, lowercase_input):\n                farewell_message = random.choice(goodbye_responses)\n                return Reply(farewell_message, goodbye=True)\n\n        # \ud83c\udfaf Try to match therapeutic patterns\n        for pattern_regex, response_templates in self.patterns:\n            pattern_match = re.match(pattern_regex, lowercase_input)\n            if pattern_match:\n                # Pick a random response template from this pattern\n                chosen_response = random.choice(response_templates)\n\n                # If the pattern captured groups, reflect and substitute them\n                if pattern_match.groups():\n                    reflected_groups = [\n                        self.__reflect(group) for group in pattern_match.groups()\n                    ]\n                    try:\n                        # Try to format the response with reflected text\n                        personalized_response = chosen_response.format(*reflected_groups)\n                        return Reply(personalized_response)\n                    except (IndexError, KeyError):\n                        # If formatting fails, just return the template as-is\n                        # (Sometimes the best therapy is keeping it simple)\n                        return Reply(chosen_response)\n                else:\n                    # No captured groups, just return the response\n                    return Reply(chosen_response)\n\n        # \ud83e\udd37\u200d\u2640\ufe0f No patterns matched - time for a generic response\n        # This is Eliza's equivalent of nodding thoughtfully\n        fallback_response = random.choice(self.default_responses)\n        return Reply(fallback_response)\n</code></pre>"},{"location":"reference/utils.eliza/#utils.eliza.Eliza-functions","title":"Functions","text":""},{"location":"reference/utils.eliza/#utils.eliza.Eliza.__init__","title":"__init__","text":"<pre><code>__init__()\n</code></pre> <p>\ud83c\udfad Initialize Eliza with her therapeutic training!</p> <p>Sets up all the patterns, responses, and reflection rules that make Eliza seem surprisingly human. Think of this as her going through therapy school, but really quickly.</p> Source code in <code>utils/eliza.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    \ud83c\udfad Initialize Eliza with her therapeutic training!\n\n    Sets up all the patterns, responses, and reflection rules\n    that make Eliza seem surprisingly human. Think of this as\n    her going through therapy school, but really quickly.\n    \"\"\"\n\n    # \ud83d\udd04 Reflection dictionary for pronoun swapping\n    # This is the secret sauce that makes \"I am sad\" become \"you are sad\"\n    self.reflections = {\n        \"am\": \"are\",\n        \"was\": \"were\",\n        \"i\": \"you\",\n        \"i'd\": \"you would\",\n        \"i've\": \"you have\",\n        \"i'll\": \"you will\",\n        \"my\": \"your\",\n        \"are\": \"am\",\n        \"you've\": \"I have\",\n        \"you'll\": \"I will\",\n        \"your\": \"my\",\n        \"yours\": \"mine\",\n        \"you\": \"I\",\n        \"me\": \"you\",\n        \"myself\": \"yourself\",\n        \"yourself\": \"myself\"\n    }\n\n    # \ud83d\udc4b Goodbye patterns - Because every therapy session must end\n    self.goodbye_patterns = [\n        (r'.*(bye|goodbye|see you|farewell|quit|exit|leave).*', [\n            \"Thank you for talking with me.\",\n            \"Good-bye. This was really a nice talk.\",\n            \"Thank you, that will be $150. Have a good day!\",  # \ud83d\udcb0 Even AI therapists have bills!\n            \"Good-bye. I hope I have helped you.\",\n            \"This was a nice session. Good-bye.\"\n        ])\n    ]\n\n    # \ud83c\udfaf Pattern-response pairs - Eliza's therapeutic toolkit\n    # Each tuple contains (regex_pattern, list_of_possible_responses)\n    self.patterns = [\n        # Apology handling - We don't need no stinkin' apologies!\n        (r'.*\\bsorry\\b.*', [\n            \"Please don't apologize.\",\n            \"Apologies are not necessary.\",\n            \"What feelings do you have when you apologize?\"\n        ]),\n\n        # Memory exploration - Let's dig into those memories\n        (r'.*\\bremember\\b (.*)', [\n            \"Do you often think of {0}?\",\n            \"Does thinking of {0} bring anything else to mind?\",\n            \"What else do you remember?\",\n            \"Why do you remember {0} just now?\"\n        ]),\n\n        # Dream analysis - Because dreams are windows to the soul, maybe\n        (r'.*\\bdream\\b.*', [\n            \"What does that dream suggest to you?\",\n            \"Do you dream often?\",\n            \"What persons appear in your dreams?\",\n            \"Are you disturbed by your dreams?\"\n        ]),\n\n        # Family therapy - It always comes back to family, doesn't it?\n        (r'.*(mother|mom|father|dad|parents|family).*', [\n            \"Tell me more about your family.\",\n            \"Who else in your family {0}?\",\n            \"Your {0}?\",\n            \"What else comes to mind when you think of your {0}?\"\n        ]),\n\n        # Emotional support - Sad feelings need validation\n        (r'.*\\b(sad|unhappy|depressed|upset)\\b.*', [\n            \"I am sorry to hear that you are {0}.\",\n            \"Do you think coming here will help you not to be {0}?\",\n            \"I'm sure it's not pleasant to be {0}.\",\n            \"Can you explain what made you {0}?\"\n        ]),\n\n        # Positive emotions - Let's explore that happiness!\n        (r'.*\\b(happy|elated|glad|better)\\b.*', [\n            \"How have I helped you to be {0}?\",\n            \"Has your treatment made you {0}?\",\n            \"What makes you {0} just now?\",\n            \"Can you explain why you are suddenly {0}?\"\n        ]),\n\n        # Belief exploration - Question those thoughts!\n        (r'.*\\b(believe|think)\\b (.*)', [\n            \"Do you really think so?\",\n            \"But you are not sure you {0}.\",\n            \"Do you really doubt you {0}?\"\n        ]),\n\n        # Affirmative responses - When they say yes\n        (r'.*(yes|yeah|yep).*', [\n            \"You seem quite positive.\",\n            \"You are sure?\",\n            \"I see.\",\n            \"I understand.\"\n        ]),\n\n        # Negative responses - When they say no\n        (r'.*(no|nope|nah).*', [\n            \"Are you saying 'No' just to be negative?\",\n            \"You are being a bit negative.\",\n            \"Why not?\",\n            \"Why 'No'?\"\n        ]),\n\n        # Self-identification - \"I am\" statements get special treatment\n        (r'.*\\bi am (.*)', [\n            \"Did you come to me because you are {0}?\",\n            \"How long have you been {0}?\",\n            \"Do you believe it is normal to be {0}?\",\n            \"Do you enjoy being {0}?\"\n        ]),\n\n        # General self-reference - Deflect back to them\n        (r'.*\\bi (.*)', [\n            \"We should be discussing you, not me.\",\n            \"Why do you say that?\",\n            \"I see.\",\n            \"And what does that tell you?\",\n            \"How does that make you feel?\"\n        ]),\n\n        # Direct statements about Eliza - Turn it around\n        (r'.*\\byou are (.*)', [\n            \"Why are you interested in whether I am {0} or not?\",\n            \"Would you prefer if I were not {0}?\",\n            \"Perhaps I am {0} in your fantasies.\",\n            \"Do you sometimes think I am {0}?\"\n        ]),\n\n        # General \"you\" statements - Deflect to patient\n        (r'.*\\byou (.*)', [\n            \"We should be discussing you, not me.\",\n            \"Oh, I {0}?\",\n            \"You're not really talking about me, are you?\",\n            \"What makes you think I {0}?\"\n        ])\n    ]\n\n    # \ud83e\udd37\u200d\u2640\ufe0f Default responses - When all else fails, be vague!\n    # These are the therapy equivalent of \"turn it off and on again\"\n    self.default_responses = [\n        \"Please tell me more.\",\n        \"Let's change focus a bit... Tell me about your family.\",\n        \"Can you elaborate on that?\",\n        \"Why do you say that?\",\n        \"I see.\",\n        \"Very interesting.\",\n        \"I see.  And what does that tell you?\",\n        \"How does that make you feel?\",\n        \"Do you feel strongly about discussing such things?\"\n    ]\n</code></pre>"},{"location":"reference/utils.eliza/#utils.eliza.Eliza.__reflect","title":"__reflect","text":"<pre><code>__reflect(text_fragment)\n</code></pre> <p>\ud83e\ude9e The magic mirror - reflect pronouns back to the user.</p> <p>This is where the therapeutic magic happens! Eliza takes what you said and reflects it back by swapping pronouns and perspective. \"I am sad\" becomes \"you are sad\", creating the illusion that she's really listening and understanding.</p> <p>Parameters:</p> Name Type Description Default <code>text_fragment</code> <code>str</code> <p>The text to reflect back</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The reflected text with pronouns swapped</p> Example <p>eliza = Eliza() eliza._Eliza__reflect(\"I am feeling happy\") \"you are feeling happy\"</p> Note <p>This method preserves punctuation while doing the reflection, because even AI therapists should have good grammar! \u2728</p> Source code in <code>utils/eliza.py</code> <pre><code>def __reflect(self, text_fragment: str) -&gt; str:\n    \"\"\"\n    \ud83e\ude9e The magic mirror - reflect pronouns back to the user.\n\n    This is where the therapeutic magic happens! Eliza takes what you\n    said and reflects it back by swapping pronouns and perspective.\n    \"I am sad\" becomes \"you are sad\", creating the illusion that\n    she's really listening and understanding.\n\n    Args:\n        text_fragment (str): The text to reflect back\n\n    Returns:\n        str: The reflected text with pronouns swapped\n\n    Example:\n        &gt;&gt;&gt; eliza = Eliza()\n        &gt;&gt;&gt; eliza._Eliza__reflect(\"I am feeling happy\")\n        \"you are feeling happy\"\n\n    Note:\n        This method preserves punctuation while doing the reflection,\n        because even AI therapists should have good grammar! \u2728\n    \"\"\"\n    # Split into individual words for processing\n    word_tokens = text_fragment.lower().split()\n    reflected_words = []\n\n    for word in word_tokens:\n        # Separate the actual word from any punctuation\n        clean_word = re.sub(r'[^\\w]', '', word)\n        punctuation = word[len(clean_word):]\n\n        # Apply reflection if we know how to transform this word\n        if clean_word in self.reflections:\n            reflected_word = self.reflections[clean_word] + punctuation\n        else:\n            reflected_word = word\n\n        reflected_words.append(reflected_word)\n\n    return ' '.join(reflected_words)\n</code></pre>"},{"location":"reference/utils.eliza/#utils.eliza.Eliza.reply","title":"reply","text":"<pre><code>reply(user_message)\n</code></pre> <p>\ud83d\udcad Generate a therapeutic response to the user's message.</p> <p>This is Eliza's main brain function! She analyzes what you said, tries to match it against her patterns, and responds with something that sounds like she actually cares (spoiler: she doesn't, but she's very good at pretending).</p> <p>Process: 1. Check if it's a goodbye message first 2. Try to match against therapeutic patterns 3. If pattern matches and has groups, reflect them back 4. If no patterns match, use a generic response 5. Add some randomness to keep things interesting</p> <p>Parameters:</p> Name Type Description Default <code>user_message</code> <code>str</code> <p>What the human said to Eliza</p> required <p>Returns:</p> Name Type Description <code>Reply</code> <code>Reply</code> <p>Eliza's thoughtful (or generic) response</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; eliza = Eliza()\n&gt;&gt;&gt; reply = eliza.reply(\"I am feeling sad\")\n&gt;&gt;&gt; reply.text\n\"Did you come to me because you are feeling sad?\"\n</code></pre> <pre><code>&gt;&gt;&gt; reply = eliza.reply(\"goodbye\")\n&gt;&gt;&gt; reply.goodbye\nTrue\n</code></pre> Note <p>Empty messages get a gentle nudge to actually say something. Even AI therapists need something to work with! \ud83e\udd37\u200d\u2640\ufe0f</p> Source code in <code>utils/eliza.py</code> <pre><code>def reply(self, user_message: str) -&gt; Reply:\n    \"\"\"\n    \ud83d\udcad Generate a therapeutic response to the user's message.\n\n    This is Eliza's main brain function! She analyzes what you said,\n    tries to match it against her patterns, and responds with something\n    that sounds like she actually cares (spoiler: she doesn't, but\n    she's very good at pretending).\n\n    Process:\n    1. Check if it's a goodbye message first\n    2. Try to match against therapeutic patterns\n    3. If pattern matches and has groups, reflect them back\n    4. If no patterns match, use a generic response\n    5. Add some randomness to keep things interesting\n\n    Args:\n        user_message (str): What the human said to Eliza\n\n    Returns:\n        Reply: Eliza's thoughtful (or generic) response\n\n    Examples:\n        &gt;&gt;&gt; eliza = Eliza()\n        &gt;&gt;&gt; reply = eliza.reply(\"I am feeling sad\")\n        &gt;&gt;&gt; reply.text\n        \"Did you come to me because you are feeling sad?\"\n\n        &gt;&gt;&gt; reply = eliza.reply(\"goodbye\")\n        &gt;&gt;&gt; reply.goodbye\n        True\n\n    Note:\n        Empty messages get a gentle nudge to actually say something.\n        Even AI therapists need something to work with! \ud83e\udd37\u200d\u2640\ufe0f\n    \"\"\"\n    # Handle empty or whitespace-only input\n    if not user_message.strip():\n        return Reply(\"Please say something.\")\n\n    # Convert to lowercase for easier pattern matching\n    lowercase_input = user_message.lower()\n\n    # \ud83d\udc4b First priority: Check for goodbye patterns\n    for goodbye_pattern, goodbye_responses in self.goodbye_patterns:\n        if re.match(goodbye_pattern, lowercase_input):\n            farewell_message = random.choice(goodbye_responses)\n            return Reply(farewell_message, goodbye=True)\n\n    # \ud83c\udfaf Try to match therapeutic patterns\n    for pattern_regex, response_templates in self.patterns:\n        pattern_match = re.match(pattern_regex, lowercase_input)\n        if pattern_match:\n            # Pick a random response template from this pattern\n            chosen_response = random.choice(response_templates)\n\n            # If the pattern captured groups, reflect and substitute them\n            if pattern_match.groups():\n                reflected_groups = [\n                    self.__reflect(group) for group in pattern_match.groups()\n                ]\n                try:\n                    # Try to format the response with reflected text\n                    personalized_response = chosen_response.format(*reflected_groups)\n                    return Reply(personalized_response)\n                except (IndexError, KeyError):\n                    # If formatting fails, just return the template as-is\n                    # (Sometimes the best therapy is keeping it simple)\n                    return Reply(chosen_response)\n            else:\n                # No captured groups, just return the response\n                return Reply(chosen_response)\n\n    # \ud83e\udd37\u200d\u2640\ufe0f No patterns matched - time for a generic response\n    # This is Eliza's equivalent of nodding thoughtfully\n    fallback_response = random.choice(self.default_responses)\n    return Reply(fallback_response)\n</code></pre>"},{"location":"reference/utils.eliza/#utils.eliza.Reply","title":"Reply  <code>dataclass</code>","text":"<p>\ud83d\udcac A thoughtful response from our AI therapist.</p> <p>This dataclass encapsulates Eliza's responses, including both the actual text and whether it's time to say goodbye. Because even AI therapists need to end sessions eventually!</p> <p>Attributes:</p> Name Type Description <code>text</code> <code>str</code> <p>The wise words from Eliza</p> <code>goodbye</code> <code>bool</code> <p>True if this response ends the conversation</p> Example <p>reply = Reply(\"How does that make you feel?\", False) reply.text \"How does that make you feel?\" reply.is_goodbye() False</p> Source code in <code>utils/eliza.py</code> <pre><code>@dataclass\nclass Reply:\n    \"\"\"\n    \ud83d\udcac A thoughtful response from our AI therapist.\n\n    This dataclass encapsulates Eliza's responses, including both the\n    actual text and whether it's time to say goodbye. Because even\n    AI therapists need to end sessions eventually!\n\n    Attributes:\n        text (str): The wise words from Eliza\n        goodbye (bool): True if this response ends the conversation\n\n    Example:\n        &gt;&gt;&gt; reply = Reply(\"How does that make you feel?\", False)\n        &gt;&gt;&gt; reply.text\n        \"How does that make you feel?\"\n        &gt;&gt;&gt; reply.is_goodbye()\n        False\n    \"\"\"\n    text: str\n    goodbye: bool = False\n\n    def is_goodbye(self) -&gt; bool:\n        \"\"\"\n        \ud83d\udeaa Check if it's time to end the therapy session.\n\n        Returns:\n            bool: True if this reply indicates the conversation should end\n\n        Note:\n            This is just a convenience method because sometimes calling\n            reply.is_goodbye() feels more natural than reply.goodbye! \ud83e\udd37\u200d\u2640\ufe0f\n        \"\"\"\n        return self.goodbye\n</code></pre>"},{"location":"reference/utils.eliza/#utils.eliza.Reply-functions","title":"Functions","text":""},{"location":"reference/utils.eliza/#utils.eliza.Reply.is_goodbye","title":"is_goodbye","text":"<pre><code>is_goodbye()\n</code></pre> <p>\ud83d\udeaa Check if it's time to end the therapy session.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if this reply indicates the conversation should end</p> Note <p>This is just a convenience method because sometimes calling reply.is_goodbye() feels more natural than reply.goodbye! \ud83e\udd37\u200d\u2640\ufe0f</p> Source code in <code>utils/eliza.py</code> <pre><code>def is_goodbye(self) -&gt; bool:\n    \"\"\"\n    \ud83d\udeaa Check if it's time to end the therapy session.\n\n    Returns:\n        bool: True if this reply indicates the conversation should end\n\n    Note:\n        This is just a convenience method because sometimes calling\n        reply.is_goodbye() feels more natural than reply.goodbye! \ud83e\udd37\u200d\u2640\ufe0f\n    \"\"\"\n    return self.goodbye\n</code></pre>"},{"location":"reference/utils.some/","title":"Utilities","text":"<p>Helper functions for CloudEvents and service simulation</p>"},{"location":"reference/utils.some/#utils.some","title":"some","text":"<p>\ud83d\udee0\ufe0f Some Utility - The Swiss Army Knife of gRPC Services</p> <p>This module provides utility functions for building CloudEvent responses and simulating service calls. Think of it as the helpful assistant that handles all the boring but necessary stuff so your main service can focus on being awesome! \u26a1</p> <p>Key Features: - CloudEvent response building with proper formatting - Service call simulation with realistic delays - Timestamp conversion utilities for protobuf integration - Background task orchestration support</p> <p>The name \"Some\" might seem mysterious, but sometimes you just need \"some\" utility functions to get the job done! \ud83d\udd27</p> <p>Author: The Utility Squad \ud83e\uddb8\u200d\u2640\ufe0f\ud83e\uddb8\u200d\u2642\ufe0f</p>"},{"location":"reference/utils.some/#utils.some-classes","title":"Classes","text":""},{"location":"reference/utils.some/#utils.some.Some","title":"Some","text":"<p>\ud83c\udfad The master of ceremonies for background operations and service simulation!</p> <p>This utility class provides essential functions for: - Building properly formatted CloudEvent responses - Simulating realistic service calls with delays - Converting between datetime formats and protobuf timestamps - Supporting the Background streaming service with progress updates</p> <p>Why \"Some\"? Because sometimes you need some help, and this class provides some very useful functions! It's like having a reliable friend who always knows how to format timestamps correctly. \ud83d\udc6f\u200d\u2640\ufe0f</p> Source code in <code>utils/some.py</code> <pre><code>class Some:\n    \"\"\"\n    \ud83c\udfad The master of ceremonies for background operations and service simulation!\n\n    This utility class provides essential functions for:\n    - Building properly formatted CloudEvent responses\n    - Simulating realistic service calls with delays\n    - Converting between datetime formats and protobuf timestamps\n    - Supporting the Background streaming service with progress updates\n\n    Why \"Some\"? Because sometimes you need some help, and this class\n    provides some very useful functions! It's like having a reliable\n    friend who always knows how to format timestamps correctly. \ud83d\udc6f\u200d\u2640\ufe0f\n    \"\"\"\n\n    def build_background_response(self, *, state: service_pb2.State, started_at: dt.datetime, completed_at: Optional[dt.datetime], responses: List[service_pb2.SomeServiceResponse]) -&gt; service_pb2.BackgroundResponse:\n        \"\"\"\n        \ud83c\udfd7\ufe0f Construct a beautifully wrapped CloudEvent response for background operations.\n\n        This method is the master builder for BackgroundResponse messages. It takes\n        your raw response data and wraps it in a proper CloudEvent envelope with\n        all the metadata bells and whistles. Because even background responses\n        deserve to look professional! \u2728\n\n        Args:\n            state: The current state of the background operation (PROCESS/COMPLETE)\n            started_at (datetime): When the background operation began\n            completed_at (datetime, optional): When it completed (None if still running)\n            responses (list): List of SomeServiceResponse messages collected so far\n\n        Returns:\n            service_pb2.BackgroundResponse: A properly formatted response with CloudEvent\n\n        CloudEvent Details:\n            - Unique UUID for each response (because every response is special)\n            - Source URN identifying this service\n            - CloudEvents v1.0 spec compliance\n            - Timestamp metadata for event tracking\n            - Protobuf payload with proper type information\n\n        Example:\n            &gt;&gt;&gt; some = Some()\n            &gt;&gt;&gt; response = some.build_background_response(\n            ...     state=service_pb2.State.STATE_PROCESS,\n            ...     started_at=datetime.now(timezone.utc),\n            ...     completed_at=None,\n            ...     responses=[]\n            ... )\n\n        Note:\n            This method uses keyword-only arguments to prevent parameter mix-ups.\n            Because nobody wants to accidentally pass completed_at as state! \ud83e\udd26\u200d\u2640\ufe0f\n        \"\"\"\n        # Create the actual response payload with all the juicy details\n        payload_event = service_pb2.BackgroundResponseEvent(\n            state=state,\n            started_at=self._to_ts(started_at),\n            completed_at=self._to_ts(completed_at) if completed_at else None,\n            responses=responses,  # All the hard-earned results from our workers\n        )\n\n        # Pack the payload into a protobuf Any message for maximum flexibility\n        any_message = Any()\n        any_message.Pack(payload_event)  # This sets the type_url automagically\n\n        # Create a timestamp for this exact moment in space-time\n        current_timestamp = self._to_ts(dt.datetime.now(dt.timezone.utc))\n\n        # Wrap everything in a fancy CloudEvent envelope \ud83d\udce8\n        cloud_event = CloudEvent(\n            id=str(uuid.uuid4()),  # Every event deserves its own unique identity\n            source=\"urn:service:basic\",  # Where this event came from\n            spec_version=\"1.0\",  # We follow the standards like good citizens\n            type=payload_event.DESCRIPTOR.full_name,  # Full protobuf message name\n            attributes={\n                \"time\": CloudEvent.CloudEventAttributeValue(ce_timestamp=current_timestamp),\n            },\n            proto_data=any_message,  # The actual payload, safely packaged\n        )\n\n        return service_pb2.BackgroundResponse(cloud_event=cloud_event)\n\n    def fake_service_response(self, service_name: str, protocol: str) -&gt; service_pb2.SomeServiceResponse:\n        \"\"\"\n        \ud83c\udfaa Simulate a realistic service call with all the drama of real networking!\n\n        This method pretends to call an external service by sleeping for a random\n        duration (because real services are unpredictable) and then returns a\n        properly formatted response. It's like method acting for microservices! \ud83c\udfad\n\n        Perfect for:\n        - Testing background processing patterns\n        - Demonstrating concurrent service calls\n        - Creating realistic delays in development\n        - Impressing your colleagues with your attention to detail\n\n        Args:\n            service_name (str): Name of the service being \"called\" (e.g., \"user-service\")\n            protocol (str): Protocol type (rest, grpc, mqtt, etc.)\n\n        Returns:\n            service_pb2.SomeServiceResponse: A realistic-looking service response\n\n        Timing:\n            Random delay between 1-3 seconds (because real services are moody)\n\n        Response Format:\n            - Unique UUID for tracking\n            - Service name and version info\n            - Protocol data wrapped in SomeServiceData\n\n        Example:\n            &gt;&gt;&gt; some = Some()\n            &gt;&gt;&gt; response = some.fake_service_response(\"auth-service\", \"grpc\")\n            &gt;&gt;&gt; response.name\n            \"auth-service\"\n            &gt;&gt;&gt; response.data.type\n            \"protocol\"\n\n        Note:\n            This method uses time.sleep() which blocks the thread! That's why\n            the Background service calls it with asyncio.to_thread() to avoid\n            blocking the event loop. Safety first! \ud83d\udee1\ufe0f\n        \"\"\"\n        # Simulate realistic network delay (1-3 seconds of \"networking\")\n        _time.sleep(random.uniform(1.0, 3.0))\n\n        # Create a realistic service response with all the proper fields\n        return service_pb2.SomeServiceResponse(\n            id=str(uuid.uuid4()),  # Every response gets its own tracking ID\n            name=service_name,     # The service we \"called\"\n            version=\"v1\",          # Always version your services, kids!\n            data=service_pb2.SomeServiceData(\n                value=str(protocol),  # What protocol we \"used\"\n                type=\"protocol\",      # Metadata about the data type\n            ),\n        )\n\n    def _to_ts(self, when: dt.datetime|int|float) -&gt; Timestamp:\n        \"\"\"\n        \u23f0 The time wizard - convert any time format to protobuf Timestamp!\n\n        This utility method handles the annoying task of converting between\n        Python datetime objects (and epoch seconds) to protobuf Timestamps.\n        It's like a universal translator for time formats! \ud83c\udf0d\n\n        Handles multiple input formats:\n        - datetime objects (timezone-aware preferred)\n        - Unix epoch seconds (int or float)\n        - Automatically converts to UTC if needed\n\n        Args:\n            time_input: The time value to convert\n                - datetime: Python datetime object\n                - int/float: Unix epoch seconds\n                - None: Returns None (for convenience)\n\n        Returns:\n            Timestamp: A properly formatted protobuf Timestamp\n\n        Raises:\n            TypeError: If the input type is not supported\n\n        Examples:\n            &gt;&gt;&gt; some = Some()\n            &gt;&gt;&gt; now = datetime.now(timezone.utc)\n            &gt;&gt;&gt; ts = some._to_ts(now)\n            &gt;&gt;&gt; isinstance(ts, Timestamp)\n            True\n\n            &gt;&gt;&gt; epoch_ts = some._to_ts(1640995200.0)  # Unix epoch\n            &gt;&gt;&gt; epoch_ts.seconds\n            1640995200\n\n        Time Zone Handling:\n            - Naive datetime objects are assumed to be UTC\n            - Timezone-aware objects are converted to UTC\n            - UTC is the only truth in distributed systems! \ud83c\udf10\n\n        Note:\n            The underscore prefix indicates this is a \"private\" method,\n            but it's so useful that we document it anyway! \ud83e\udd2b\n        \"\"\"\n        ts = Timestamp()\n        if isinstance(when, dt.datetime):\n            # Ensure timezone-aware UTC\n            if when.tzinfo is None:\n                when = when.replace(tzinfo=dt.timezone.utc)\n            else:\n                when = when.astimezone(dt.timezone.utc)\n            ts.FromDatetime(when)\n        elif isinstance(when, (int, float)):\n            seconds = int(when)\n            nanos = int((when - seconds) * 1_000_000_000)\n            ts.seconds = seconds\n            ts.nanos = nanos\n        else:\n            raise TypeError(\"to_ts expects a datetime or epoch seconds (int/float)\")\n        return ts\n</code></pre>"},{"location":"reference/utils.some/#utils.some.Some-functions","title":"Functions","text":""},{"location":"reference/utils.some/#utils.some.Some.build_background_response","title":"build_background_response","text":"<pre><code>build_background_response(*, state, started_at, completed_at, responses)\n</code></pre> <p>\ud83c\udfd7\ufe0f Construct a beautifully wrapped CloudEvent response for background operations.</p> <p>This method is the master builder for BackgroundResponse messages. It takes your raw response data and wraps it in a proper CloudEvent envelope with all the metadata bells and whistles. Because even background responses deserve to look professional! \u2728</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>State</code> <p>The current state of the background operation (PROCESS/COMPLETE)</p> required <code>started_at</code> <code>datetime</code> <p>When the background operation began</p> required <code>completed_at</code> <code>datetime</code> <p>When it completed (None if still running)</p> required <code>responses</code> <code>list</code> <p>List of SomeServiceResponse messages collected so far</p> required <p>Returns:</p> Type Description <code>BackgroundResponse</code> <p>service_pb2.BackgroundResponse: A properly formatted response with CloudEvent</p> CloudEvent Details <ul> <li>Unique UUID for each response (because every response is special)</li> <li>Source URN identifying this service</li> <li>CloudEvents v1.0 spec compliance</li> <li>Timestamp metadata for event tracking</li> <li>Protobuf payload with proper type information</li> </ul> Example <p>some = Some() response = some.build_background_response( ...     state=service_pb2.State.STATE_PROCESS, ...     started_at=datetime.now(timezone.utc), ...     completed_at=None, ...     responses=[] ... )</p> Note <p>This method uses keyword-only arguments to prevent parameter mix-ups. Because nobody wants to accidentally pass completed_at as state! \ud83e\udd26\u200d\u2640\ufe0f</p> Source code in <code>utils/some.py</code> <pre><code>def build_background_response(self, *, state: service_pb2.State, started_at: dt.datetime, completed_at: Optional[dt.datetime], responses: List[service_pb2.SomeServiceResponse]) -&gt; service_pb2.BackgroundResponse:\n    \"\"\"\n    \ud83c\udfd7\ufe0f Construct a beautifully wrapped CloudEvent response for background operations.\n\n    This method is the master builder for BackgroundResponse messages. It takes\n    your raw response data and wraps it in a proper CloudEvent envelope with\n    all the metadata bells and whistles. Because even background responses\n    deserve to look professional! \u2728\n\n    Args:\n        state: The current state of the background operation (PROCESS/COMPLETE)\n        started_at (datetime): When the background operation began\n        completed_at (datetime, optional): When it completed (None if still running)\n        responses (list): List of SomeServiceResponse messages collected so far\n\n    Returns:\n        service_pb2.BackgroundResponse: A properly formatted response with CloudEvent\n\n    CloudEvent Details:\n        - Unique UUID for each response (because every response is special)\n        - Source URN identifying this service\n        - CloudEvents v1.0 spec compliance\n        - Timestamp metadata for event tracking\n        - Protobuf payload with proper type information\n\n    Example:\n        &gt;&gt;&gt; some = Some()\n        &gt;&gt;&gt; response = some.build_background_response(\n        ...     state=service_pb2.State.STATE_PROCESS,\n        ...     started_at=datetime.now(timezone.utc),\n        ...     completed_at=None,\n        ...     responses=[]\n        ... )\n\n    Note:\n        This method uses keyword-only arguments to prevent parameter mix-ups.\n        Because nobody wants to accidentally pass completed_at as state! \ud83e\udd26\u200d\u2640\ufe0f\n    \"\"\"\n    # Create the actual response payload with all the juicy details\n    payload_event = service_pb2.BackgroundResponseEvent(\n        state=state,\n        started_at=self._to_ts(started_at),\n        completed_at=self._to_ts(completed_at) if completed_at else None,\n        responses=responses,  # All the hard-earned results from our workers\n    )\n\n    # Pack the payload into a protobuf Any message for maximum flexibility\n    any_message = Any()\n    any_message.Pack(payload_event)  # This sets the type_url automagically\n\n    # Create a timestamp for this exact moment in space-time\n    current_timestamp = self._to_ts(dt.datetime.now(dt.timezone.utc))\n\n    # Wrap everything in a fancy CloudEvent envelope \ud83d\udce8\n    cloud_event = CloudEvent(\n        id=str(uuid.uuid4()),  # Every event deserves its own unique identity\n        source=\"urn:service:basic\",  # Where this event came from\n        spec_version=\"1.0\",  # We follow the standards like good citizens\n        type=payload_event.DESCRIPTOR.full_name,  # Full protobuf message name\n        attributes={\n            \"time\": CloudEvent.CloudEventAttributeValue(ce_timestamp=current_timestamp),\n        },\n        proto_data=any_message,  # The actual payload, safely packaged\n    )\n\n    return service_pb2.BackgroundResponse(cloud_event=cloud_event)\n</code></pre>"},{"location":"reference/utils.some/#utils.some.Some.fake_service_response","title":"fake_service_response","text":"<pre><code>fake_service_response(service_name, protocol)\n</code></pre> <p>\ud83c\udfaa Simulate a realistic service call with all the drama of real networking!</p> <p>This method pretends to call an external service by sleeping for a random duration (because real services are unpredictable) and then returns a properly formatted response. It's like method acting for microservices! \ud83c\udfad</p> <p>Perfect for: - Testing background processing patterns - Demonstrating concurrent service calls - Creating realistic delays in development - Impressing your colleagues with your attention to detail</p> <p>Parameters:</p> Name Type Description Default <code>service_name</code> <code>str</code> <p>Name of the service being \"called\" (e.g., \"user-service\")</p> required <code>protocol</code> <code>str</code> <p>Protocol type (rest, grpc, mqtt, etc.)</p> required <p>Returns:</p> Type Description <code>SomeServiceResponse</code> <p>service_pb2.SomeServiceResponse: A realistic-looking service response</p> Timing <p>Random delay between 1-3 seconds (because real services are moody)</p> Response Format <ul> <li>Unique UUID for tracking</li> <li>Service name and version info</li> <li>Protocol data wrapped in SomeServiceData</li> </ul> Example <p>some = Some() response = some.fake_service_response(\"auth-service\", \"grpc\") response.name \"auth-service\" response.data.type \"protocol\"</p> Note <p>This method uses time.sleep() which blocks the thread! That's why the Background service calls it with asyncio.to_thread() to avoid blocking the event loop. Safety first! \ud83d\udee1\ufe0f</p> Source code in <code>utils/some.py</code> <pre><code>def fake_service_response(self, service_name: str, protocol: str) -&gt; service_pb2.SomeServiceResponse:\n    \"\"\"\n    \ud83c\udfaa Simulate a realistic service call with all the drama of real networking!\n\n    This method pretends to call an external service by sleeping for a random\n    duration (because real services are unpredictable) and then returns a\n    properly formatted response. It's like method acting for microservices! \ud83c\udfad\n\n    Perfect for:\n    - Testing background processing patterns\n    - Demonstrating concurrent service calls\n    - Creating realistic delays in development\n    - Impressing your colleagues with your attention to detail\n\n    Args:\n        service_name (str): Name of the service being \"called\" (e.g., \"user-service\")\n        protocol (str): Protocol type (rest, grpc, mqtt, etc.)\n\n    Returns:\n        service_pb2.SomeServiceResponse: A realistic-looking service response\n\n    Timing:\n        Random delay between 1-3 seconds (because real services are moody)\n\n    Response Format:\n        - Unique UUID for tracking\n        - Service name and version info\n        - Protocol data wrapped in SomeServiceData\n\n    Example:\n        &gt;&gt;&gt; some = Some()\n        &gt;&gt;&gt; response = some.fake_service_response(\"auth-service\", \"grpc\")\n        &gt;&gt;&gt; response.name\n        \"auth-service\"\n        &gt;&gt;&gt; response.data.type\n        \"protocol\"\n\n    Note:\n        This method uses time.sleep() which blocks the thread! That's why\n        the Background service calls it with asyncio.to_thread() to avoid\n        blocking the event loop. Safety first! \ud83d\udee1\ufe0f\n    \"\"\"\n    # Simulate realistic network delay (1-3 seconds of \"networking\")\n    _time.sleep(random.uniform(1.0, 3.0))\n\n    # Create a realistic service response with all the proper fields\n    return service_pb2.SomeServiceResponse(\n        id=str(uuid.uuid4()),  # Every response gets its own tracking ID\n        name=service_name,     # The service we \"called\"\n        version=\"v1\",          # Always version your services, kids!\n        data=service_pb2.SomeServiceData(\n            value=str(protocol),  # What protocol we \"used\"\n            type=\"protocol\",      # Metadata about the data type\n        ),\n    )\n</code></pre>"}]}